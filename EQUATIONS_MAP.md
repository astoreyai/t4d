# T4DM Equations Map

**Purpose**: Map each implementation task to required equations, their status, and verification criteria.

---

## Equation Status Legend

| Status | Meaning |
|--------|---------|
| âœ… EXISTS | Proven, can use directly |
| ðŸ”§ ADAPT | Exists but needs modification |
| ðŸ”¬ INVENT | Must be developed and proven |

---

## Track B: Temporal Encoding

### B1.1 Time2Vec Encoder

**Equation**:
```
t2v(Ï„)[i] = {
    Ï‰_i Â· Ï„ + Ï†_i,           if i = 0 (linear)
    sin(Ï‰_i Â· Ï„ + Ï†_i),      if 1 â‰¤ i â‰¤ k (periodic)
}
```
**Status**: âœ… EXISTS
**Verification**:
- Gradients flow correctly
- Frequencies learnable
- Covers target time range

**Extension** (2025 improvement):
```
t2v_extended(Ï„)[i] = sin(Ï‰_i Â· Ï„ + Ï†_i) + cos(Ï‰_i Â· Ï„ + Ï†_i)
```
**Status**: âœ… EXISTS (TT2VFin, 2025)

---

### B1.2 Time2Vec Decoder

**Equation**: Timestamp recovery
```
Ï„_recovered = (arcsin(t2v(Ï„)[i]) - Ï†_i) / Ï‰_i
```
**Status**: ðŸ”§ ADAPT
**Problem**: Periodic ambiguity (arcsin has multiple solutions)
**Solution**: Constrain to valid time window, use linear component

**Verification**:
- < 1% error on synthetic data
- Handles edge cases (t=0, t=max)

---

### B1.3 Multi-Scale Encoding

**Equation**: Hierarchical temporal encoding
```
t_multi(Ï„) = concat([
    t2v(Ï„, Ï„_hour),      # hourly patterns
    t2v(Ï„, Ï„_day),       # daily patterns
    t2v(Ï„, Ï„_week),      # weekly patterns
    t2v(Ï„, Ï„_year)       # yearly patterns
])
```
**Status**: âœ… EXISTS (MultiTEmb, 2025)
**Verification**: Each scale captures appropriate patterns

---

### B1.4 Weber-Scaled Temporal Basis

**Equation**: Log-compressed time cells
```
temporal_basis(t) = log(1 + t/Ï„_base)
```
**Status**: âœ… EXISTS (Temporal Context Model)
**Verification**: Matches Weber's law for time perception

---

## Track B2: Memory Consolidation

### B2.1 Weighted Averaging Consolidation

**Equation**:
```
v_consolidated = Î£áµ¢ wáµ¢ Â· váµ¢ / Î£áµ¢ wáµ¢
```
**Status**: âœ… EXISTS
**Optimality**: Optimal for LÂ² loss under Gaussian noise
**Verification**: Gist preserved, details lost (as expected)

---

### B2.2 Importance Weighting

**Equation**:
```
wáµ¢ = importance(máµ¢) Ã— recency(táµ¢) Ã— relevance(máµ¢, context)
importance(m) = access_count(m) Ã— avg_attention(m)
recency(t) = exp(-(t_now - t) / Ï„_decay)
```
**Status**: ðŸ”§ ADAPT (combine existing components)
**Verification**: High-importance memories have higher weights

---

### B2.3 Rate-Distortion Consolidation

**Equation**:
```
L = ||v - decode(encode(v))||Â² + Î» Â· H(encode(v))
```
Where H is entropy (compression rate)

**Status**: ðŸ”¬ INVENT (novel application)
**Verification**:
- Compression ratio measurable
- Reconstruction error bounded
- Pareto frontier documented

---

### B2.4 Interference Detection

**Equation**:
```
interference(m_new, M_existing) = max_{m âˆˆ M} cosine_sim(m_new, m)
if interference > Î¸: trigger_pattern_separation()
```
**Status**: âœ… EXISTS
**Verification**: High-similarity memories flagged

---

## Track B3: Associative Decoding

### B3.1 Modern Hopfield Retrieval

**Equation**:
```
E = -log(Î£áµ¢ exp(xáµ¢áµ€ Â· query))
update = softmax(Î² Â· Xáµ€ Â· query) Â· X
```
**Status**: âœ… EXISTS (Ramsauer 2020)
**Capacity**: O(d^(n-1)) for n-th order
**Verification**: Retrieval accuracy >95%

---

### B3.2 Pattern Completion

**Equation**:
```
v_complete = hopfield_update(v_partial, M, iterations=k)
```
**Status**: âœ… EXISTS
**Verification**: Works with 50% masking

---

## Track L: Learning Systems

### L1.1 STDP Learning Rule

**Equation**:
```
Î”w = {
    Aâ‚Š Â· exp(-Î”t/Ï„â‚Š),  if Î”t > 0 (pre before post â†’ LTP)
    -Aâ‚‹ Â· exp(Î”t/Ï„â‚‹),  if Î”t < 0 (post before pre â†’ LTD)
}
```
**Status**: âœ… EXISTS
**Adaptation**: Scale Ï„ from milliseconds to seconds/minutes
**Verification**: Co-retrieved memories strengthen connections

---

### L2.2 Pattern Separation

**Equation**:
```
v_separated = v + noise Â· (v - nearest_neighbor(v, M))
```
Or via sparse coding:
```
minimize ||v - D Â· s||Â² + Î» ||s||â‚
```
**Status**: âœ… EXISTS
**Verification**: Separated vectors are more orthogonal

---

## Open Research Questions

### Event Segmentation

**Problem**: Where does one memory end and another begin?
**Current**: Heuristic (fixed time windows, change detection)
**Needed**:
```
boundary_score(t) = f(Î”embedding(t), Î”attention(t), Î”topic(t))
segment if boundary_score(t) > Î¸
```
**Status**: ðŸ”¬ INVENT
**Research**: Theta-gated windows (~125ms in biology)

---

## Verification Checklist

### Mathematical Proofs Required

| Equation | Proof Type | Status |
|----------|------------|--------|
| Time2Vec decoder | Error bounds | ðŸ”§ Needs bounds |
| Rate-distortion consolidation | Optimality | ðŸ”¬ To prove |
| Hopfield capacity | Capacity formula | âœ… Proven |

### Empirical Verification Required

| Equation | Test Type | Dataset |
|----------|-----------|---------|
| Time2Vec | Reconstruction error | Synthetic timestamps |
| Consolidation | Gist preservation | Conversation memory |
| Pattern completion | Reconstruction | Masked retrieval |
| STDP | Connection strength | Co-retrieval logs |

---

## Summary: Equations by Status

| Status | Count | Examples |
|--------|-------|----------|
| âœ… EXISTS | 10 | Time2Vec, Hopfield, STDP, Weber basis |
| ðŸ”§ ADAPT | 2 | Time2Vec decoder, Importance weighting |
| ðŸ”¬ INVENT | 2 | Rate-distortion, Event segmentation |

**Bottom Line**: 10 equations exist, 2 need adaptation, 2 need invention.
