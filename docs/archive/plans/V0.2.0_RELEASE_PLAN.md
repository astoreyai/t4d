# T4DM v0.2.0 Release Plan

**Version**: 0.1.0 → 0.2.0
**Codename**: Python SDK Release
**Target**: Production-Ready Python Framework
**Status**: Planning

---

## Executive Summary

Complete transformation of T4DM into a production-ready, well-documented Python framework with:
- Full test coverage (90%+)
- LLM-friendly documentation
- Comprehensive examples
- Security hardening
- API documentation endpoint
- All reviewer recommendations implemented

---

## Release Scope

| Category | Items | Effort |
|----------|-------|--------|
| P0: Critical | 6 tasks | 5 days |
| P1: High Priority | 8 tasks | 13.5 days |
| P2: Medium Priority | 5 tasks | 7 days |
| P3: Future (included) | 5 tasks | 15 days |
| Testing | Full coverage | 5 days |
| Documentation | Complete | 5 days |
| Examples | 10+ examples | 3 days |
| Security | Audit + fixes | 2 days |
| **Total** | | **~55 days** |

---

## Table of Contents

1. [P0: Critical](#p0-critical)
2. [P1: High Priority](#p1-high-priority)
3. [P2: Medium Priority](#p2-medium-priority)
4. [P3: Advanced Features](#p3-advanced-features)
5. [Testing Requirements](#testing-requirements)
6. [Documentation Requirements](#documentation-requirements)
7. [Examples](#examples)
8. [Security](#security)
9. [API Documentation Endpoint](#api-documentation-endpoint)
10. [Release Artifacts](#release-artifacts)

---

## P0: Critical

### P0-1: Remove MCP Gateway
**Effort**: 1 day | **LOC**: -10,000

```
DELETE:
├── src/t4dm/mcp/                    # 2,827 LOC
│   ├── __init__.py
│   ├── errors.py
│   ├── types.py
│   ├── gateway.py
│   ├── schema.py
│   ├── resources.py
│   ├── server.py
│   ├── compat.py
│   ├── memory_gateway.py
│   ├── persistent_server.py
│   ├── validation.py
│   └── tools/
│       ├── __init__.py
│       ├── episodic.py
│       ├── semantic.py
│       ├── procedural.py
│       ├── bioinspired.py
│       └── system.py
├── tests/mcp/                     # 5,612 LOC
├── tests/unit/test_mcp_gateway.py
├── tests/test_mcp_types.py
├── tests/hooks/test_mcp.py
└── src/t4dm/hooks/mcp.py
```

**Tasks**:
- [ ] Delete all MCP source files
- [ ] Delete all MCP test files
- [ ] Remove MCP from pyproject.toml dependencies
- [ ] Remove MCP exports from src/t4dm/__init__.py
- [ ] Fix all broken imports
- [ ] Run full test suite
- [ ] Update CHANGELOG

---

### P0-2: CLI Entry Point
**Effort**: 1 day | **LOC**: +500

**File**: `src/t4dm/cli.py`

```python
"""
T4DM CLI.

Usage:
    ww init                    # Initialize ~/.t4dm/
    ww store "content"         # Store episode
    ww recall "query"          # Recall memories
    t4dm consolidate             # Run sleep cycle
    t4dm serve                   # Start API server
    ww doctor                  # Check dependencies
    ww status                  # Show system status
    t4dm config [key] [value]    # Get/set config
    ww checkpoint [name]       # Save state
    ww restore [name]          # Restore state
    ww tune                    # RL tuning operations
    ww introspect              # Show learning state
    ww metrics                 # Show performance metrics
    ww infra up|down|status    # Manage infrastructure
"""
import typer
from rich.console import Console
from rich.table import Table

app = typer.Typer(
    name="ww",
    help="T4DM - Biologically-inspired memory for AI",
    add_completion=True,
)

console = Console()

@app.command()
def init(
    path: str = typer.Option("~/.ww", help="Config directory path"),
    force: bool = typer.Option(False, help="Overwrite existing config"),
):
    """Initialize T4DM configuration."""
    ...

@app.command()
def store(
    content: str = typer.Argument(..., help="Content to store"),
    tags: list[str] = typer.Option([], help="Tags for the memory"),
    importance: float = typer.Option(0.5, help="Importance score 0-1"),
):
    """Store an episode in memory."""
    ...

@app.command()
def recall(
    query: str = typer.Argument(..., help="Query to search for"),
    k: int = typer.Option(5, help="Number of results"),
    memory_type: str = typer.Option("all", help="episodic|semantic|procedural|all"),
    format: str = typer.Option("table", help="table|json|plain"),
):
    """Recall memories matching query."""
    ...

@app.command()
def consolidate(
    full: bool = typer.Option(False, help="Run full consolidation cycle"),
    dry_run: bool = typer.Option(False, help="Show what would be consolidated"),
):
    """Run memory consolidation (sleep cycle)."""
    ...

@app.command()
def serve(
    host: str = typer.Option("0.0.0.0", help="Host to bind"),
    port: int = typer.Option(8420, help="Port to bind"),
    reload: bool = typer.Option(False, help="Auto-reload on changes"),
):
    """Start the REST API server."""
    ...

@app.command()
def doctor():
    """Check system dependencies and health."""
    ...

@app.command()
def status():
    """Show system status and statistics."""
    ...

@app.command()
def config(
    key: str = typer.Argument(None, help="Config key to get/set"),
    value: str = typer.Argument(None, help="Value to set"),
):
    """Get or set configuration values."""
    ...

@app.command()
def checkpoint(
    name: str = typer.Argument("default", help="Checkpoint name"),
):
    """Save current learning state."""
    ...

@app.command()
def restore(
    name: str = typer.Argument("default", help="Checkpoint to restore"),
):
    """Restore learning state from checkpoint."""
    ...

@app.command()
def tune(
    action: str = typer.Argument(..., help="train|evaluate|export"),
    epochs: int = typer.Option(1, help="Training epochs"),
):
    """RL tuning operations."""
    ...

@app.command()
def introspect():
    """Show current learning system state."""
    ...

@app.command()
def metrics(
    period: str = typer.Option("24h", help="Time period"),
    format: str = typer.Option("table", help="table|json|prometheus"),
):
    """Show performance metrics."""
    ...

@app.command()
def infra(
    action: str = typer.Argument(..., help="up|down|status"),
):
    """Manage infrastructure (Neo4j, Qdrant)."""
    ...

if __name__ == "__main__":
    app()
```

**Tests**: `tests/unit/test_cli.py` (30+ tests)

---

### P0-3: Configuration Layer
**Effort**: 0.5 days | **LOC**: +400

**File**: `src/t4dm/config.py`

```python
"""
T4DM Configuration.

Priority (highest to lowest):
1. CLI arguments
2. Environment variables (T4DM_*)
3. Project config (./.t4dm/config.yaml)
4. User config (~/.t4dm/config.yaml)
5. Defaults
"""
from pathlib import Path
from pydantic import BaseModel, Field
from pydantic_settings import BaseSettings

class Neo4jConfig(BaseModel):
    uri: str = "bolt://localhost:7687"
    user: str = "neo4j"
    password: str = ""
    database: str = "neo4j"
    max_connection_pool_size: int = 50

class QdrantConfig(BaseModel):
    host: str = "localhost"
    port: int = 6333
    grpc_port: int = 6334
    api_key: str | None = None
    https: bool = False

class EmbeddingConfig(BaseModel):
    model: str = "BAAI/bge-m3"
    dimension: int = 1024
    batch_size: int = 32
    cache_size: int = 10000

class ConsolidationConfig(BaseModel):
    enabled: bool = True
    interval_seconds: int = 3600
    use_prioritized_replay: bool = True
    surprise_threshold: float = 0.3
    replay_batch_size: int = 100

class NeuromodulatorConfig(BaseModel):
    enable_meta_learning: bool = True
    meta_learning_rate: float = 0.001
    ach_encoding_factor: float = 1.5
    ach_retrieval_factor: float = 0.6
    ne_novelty_threshold: float = 0.3

class APIConfig(BaseModel):
    host: str = "0.0.0.0"
    port: int = 8420
    workers: int = 4
    cors_origins: list[str] = ["*"]
    rate_limit: int = 100  # requests per minute
    docs_enabled: bool = True

class LoggingConfig(BaseModel):
    level: str = "INFO"
    format: str = "json"  # json or text
    file: str | None = None

class WWConfig(BaseSettings):
    """T4DM configuration."""

    # Sub-configs
    neo4j: Neo4jConfig = Field(default_factory=Neo4jConfig)
    qdrant: QdrantConfig = Field(default_factory=QdrantConfig)
    embedding: EmbeddingConfig = Field(default_factory=EmbeddingConfig)
    consolidation: ConsolidationConfig = Field(default_factory=ConsolidationConfig)
    neuromodulator: NeuromodulatorConfig = Field(default_factory=NeuromodulatorConfig)
    api: APIConfig = Field(default_factory=APIConfig)
    logging: LoggingConfig = Field(default_factory=LoggingConfig)

    # Paths
    config_dir: Path = Path.home() / ".ww"
    state_dir: Path = Path.home() / ".ww" / "state"
    logs_dir: Path = Path.home() / ".ww" / "logs"

    class Config:
        env_prefix = "T4DM_"
        env_nested_delimiter = "__"

    @classmethod
    def load(cls) -> "WWConfig":
        """Load configuration from all sources."""
        ...

    def save(self) -> None:
        """Save configuration to user config file."""
        ...
```

**Directory Structure**:
```
~/.t4dm/
├── config.yaml              # User configuration
├── state/                   # Learning state checkpoints
│   ├── default/
│   │   ├── dopamine.json
│   │   ├── neuromodulators.json
│   │   ├── gate.json
│   │   ├── meta_params.json
│   │   └── manifest.json
│   └── checkpoints/
│       └── 2026-01-02_1200/
├── logs/                    # Log files
│   └── ww.log
└── cache/                   # Embedding cache
    └── embeddings.db
```

---

### P0-4: Simplified Python API
**Effort**: 1 day | **LOC**: +600

**File**: `src/t4dm/api.py`

```python
"""
Simplified T4DM API.

Usage:
    from ww import memory

    # Store
    memory.store("I learned Python today", tags=["learning"])

    # Recall
    results = memory.recall("What did I learn?", k=5)

    # Consolidate
    memory.consolidate()

    # Introspect
    state = memory.introspect()
    print(state.dopamine_level)
"""
from __future__ import annotations
import asyncio
from typing import Any, Optional
from dataclasses import dataclass
from contextlib import asynccontextmanager

@dataclass
class RecallResult:
    """Result from memory recall."""
    id: str
    content: str
    score: float
    memory_type: str
    metadata: dict[str, Any]
    created_at: str

@dataclass
class IntrospectionResult:
    """Current learning system state."""
    dopamine_level: float
    acetylcholine_mode: str  # "encoding" or "retrieval"
    norepinephrine_level: float
    serotonin_level: float
    recent_rpe: list[float]
    consolidation_pending: int
    total_episodes: int
    total_concepts: int
    total_skills: int

class Memory:
    """
    Simplified memory interface.

    Thread-safe singleton that auto-initializes on first use.
    """

    _instance: Optional["Memory"] = None
    _lock: asyncio.Lock = asyncio.Lock()

    def __new__(cls) -> "Memory":
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def _ensure_initialized(self) -> None:
        """Lazy initialization on first use."""
        if not self._initialized:
            self._initialize()

    def _initialize(self) -> None:
        """Initialize backends and load state."""
        from t4dm.config import WWConfig
        from t4dm.core import T4DM

        self._config = WWConfig.load()
        self._ww = T4DM(self._config)
        self._loop = asyncio.new_event_loop()
        self._initialized = True

    # Sync API
    def store(
        self,
        content: str,
        *,
        tags: list[str] | None = None,
        importance: float = 0.5,
        context: dict[str, Any] | None = None,
    ) -> str:
        """Store an episode. Returns episode ID."""
        self._ensure_initialized()
        return self._loop.run_until_complete(
            self.astore(content, tags=tags, importance=importance, context=context)
        )

    def recall(
        self,
        query: str,
        *,
        k: int = 5,
        memory_type: str = "all",
        min_score: float = 0.0,
    ) -> list[RecallResult]:
        """Recall memories matching query."""
        self._ensure_initialized()
        return self._loop.run_until_complete(
            self.arecall(query, k=k, memory_type=memory_type, min_score=min_score)
        )

    def consolidate(self, *, full: bool = False) -> dict[str, int]:
        """Run consolidation cycle. Returns stats."""
        self._ensure_initialized()
        return self._loop.run_until_complete(self.aconsolidate(full=full))

    def introspect(self) -> IntrospectionResult:
        """Get current learning system state."""
        self._ensure_initialized()
        return self._loop.run_until_complete(self.aintrospect())

    def feedback(
        self,
        memory_id: str,
        *,
        positive: bool,
        magnitude: float = 1.0,
    ) -> None:
        """Provide feedback on a memory retrieval."""
        self._ensure_initialized()
        return self._loop.run_until_complete(
            self.afeedback(memory_id, positive=positive, magnitude=magnitude)
        )

    # Async API
    async def astore(
        self,
        content: str,
        *,
        tags: list[str] | None = None,
        importance: float = 0.5,
        context: dict[str, Any] | None = None,
    ) -> str:
        """Async: Store an episode."""
        ...

    async def arecall(
        self,
        query: str,
        *,
        k: int = 5,
        memory_type: str = "all",
        min_score: float = 0.0,
    ) -> list[RecallResult]:
        """Async: Recall memories."""
        ...

    async def aconsolidate(self, *, full: bool = False) -> dict[str, int]:
        """Async: Run consolidation."""
        ...

    async def aintrospect(self) -> IntrospectionResult:
        """Async: Get learning state."""
        ...

    async def afeedback(
        self,
        memory_id: str,
        *,
        positive: bool,
        magnitude: float = 1.0,
    ) -> None:
        """Async: Provide feedback."""
        ...

# Singleton instance
memory = Memory()

# Convenience exports
def store(*args, **kwargs):
    return memory.store(*args, **kwargs)

def recall(*args, **kwargs):
    return memory.recall(*args, **kwargs)

def consolidate(*args, **kwargs):
    return memory.consolidate(*args, **kwargs)

def introspect():
    return memory.introspect()

def feedback(*args, **kwargs):
    return memory.feedback(*args, **kwargs)
```

**Update** `src/t4dm/__init__.py`:
```python
"""
T4DM - Biologically-inspired memory for AI.

Quick Start:
    from ww import memory

    memory.store("I learned something today")
    results = memory.recall("What did I learn?")

Advanced:
    from ww import T4DM

    ww = T4DM(config)
    await ww.episodic.store(...)
"""
__version__ = "0.2.0"

from t4dm.api import (
    memory,
    store,
    recall,
    consolidate,
    introspect,
    feedback,
    RecallResult,
    IntrospectionResult,
)
from t4dm.core import T4DM
from t4dm.config import WWConfig

__all__ = [
    # Simple API
    "memory",
    "store",
    "recall",
    "consolidate",
    "introspect",
    "feedback",
    # Types
    "RecallResult",
    "IntrospectionResult",
    # Advanced
    "T4DM",
    "WWConfig",
    # Meta
    "__version__",
]
```

---

### P0-5: PyPI Publishing
**Effort**: 0.5 days | **LOC**: +100

**File**: `pyproject.toml`

```toml
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "t4dm"
version = "0.2.0"
description = "Biologically-inspired memory system for AI agents"
readme = "README.md"
license = {file = "LICENSE"}
authors = [
    {name = "Aaron Storey", email = "aaron@example.com"}
]
maintainers = [
    {name = "Aaron Storey", email = "aaron@example.com"}
]
keywords = [
    "memory",
    "ai",
    "artificial-intelligence",
    "cognitive-architecture",
    "neuroscience",
    "hippocampus",
    "neuromodulation",
    "reinforcement-learning",
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Typing :: Typed",
]
requires-python = ">=3.10"
dependencies = [
    "numpy>=1.24",
    "pydantic>=2.0",
    "pydantic-settings>=2.0",
    "pyyaml>=6.0",
    "typer>=0.9",
    "rich>=13.0",
    "httpx>=0.25",
    "aiofiles>=23.0",
]

[project.optional-dependencies]
production = [
    "neo4j>=5.0",
    "qdrant-client>=1.7",
    "torch>=2.0",
    "transformers>=4.30",
    "sentence-transformers>=2.2",
]
api = [
    "fastapi>=0.109",
    "uvicorn>=0.25",
    "python-multipart>=0.0.6",
]
consolidation = [
    "hdbscan>=0.8.33",
    "scikit-learn>=1.3",
]
dev = [
    "pytest>=7.4",
    "pytest-asyncio>=0.21",
    "pytest-cov>=4.1",
    "hypothesis>=6.88",
    "mypy>=1.7",
    "ruff>=0.1",
    "pre-commit>=3.5",
]
docs = [
    "mkdocs>=1.5",
    "mkdocs-material>=9.4",
    "mkdocstrings[python]>=0.24",
]
all = [
    "t4dm[production,api,consolidation,dev,docs]",
]

[project.scripts]
ww = "t4dm.cli:app"

[project.urls]
Homepage = "https://github.com/astoreyai/t4dm"
Documentation = "https://t4dm.readthedocs.io"
Repository = "https://github.com/astoreyai/t4dm"
Changelog = "https://github.com/astoreyai/t4dm/blob/main/CHANGELOG.md"
Issues = "https://github.com/astoreyai/t4dm/issues"

[tool.hatch.build.targets.wheel]
packages = ["src/ww"]

[tool.hatch.build.targets.sdist]
include = [
    "/src",
    "/tests",
    "/docs",
    "/examples",
]

[tool.pytest.ini_options]
asyncio_mode = "auto"
testpaths = ["tests"]
addopts = "-v --cov=src/ww --cov-report=term-missing"

[tool.mypy]
python_version = "3.11"
strict = true
warn_return_any = true
warn_unused_configs = true

[tool.ruff]
line-length = 100
target-version = "py311"

[tool.ruff.lint]
select = ["E", "F", "I", "N", "W", "UP", "B", "C4", "SIM"]
```

**GitHub Actions**: `.github/workflows/publish.yml`

```yaml
name: Publish to PyPI

on:
  release:
    types: [published]

jobs:
  publish:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Build
        run: |
          pip install build
          python -m build
      - name: Publish to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          password: ${{ secrets.PYPI_API_TOKEN }}
```

---

### P0-6: Docker Compose + Infrastructure
**Effort**: 0.5 days | **LOC**: +200

**File**: `docker/docker-compose.yml`

```yaml
version: "3.8"

services:
  neo4j:
    image: neo4j:5.15-community
    container_name: ww-neo4j
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    environment:
      NEO4J_AUTH: neo4j/worldweaver
      NEO4J_PLUGINS: '["apoc"]'
      NEO4J_dbms_memory_heap_max__size: 1G
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7474"]
      interval: 10s
      timeout: 5s
      retries: 5

  qdrant:
    image: qdrant/qdrant:v1.7.4
    container_name: ww-qdrant
    ports:
      - "6333:6333"  # REST
      - "6334:6334"  # gRPC
    volumes:
      - qdrant_data:/qdrant/storage
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  ww-api:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: ww-api
    ports:
      - "8420:8420"
    environment:
      T4DM_NEO4J__URI: bolt://neo4j:7687
      T4DM_NEO4J__USER: neo4j
      T4DM_NEO4J__PASSWORD: worldweaver
      T4DM_QDRANT__HOST: qdrant
      T4DM_QDRANT__PORT: 6333
      T4DM_API__DOCS_ENABLED: "true"
    depends_on:
      neo4j:
        condition: service_healthy
      qdrant:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8420/health"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  neo4j_data:
  neo4j_logs:
  qdrant_data:
```

**File**: `docker/Dockerfile`

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies
COPY pyproject.toml .
RUN pip install --no-cache-dir ".[production,api,consolidation]"

# Copy source
COPY src/ src/

# Create non-root user
RUN useradd -m -u 1000 ww
USER ww

# Expose port
EXPOSE 8420

# Health check
HEALTHCHECK --interval=30s --timeout=5s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8420/health || exit 1

# Run
CMD ["ww", "serve", "--host", "0.0.0.0", "--port", "8420"]
```

---

## P1: High Priority

### P1-1: Replace HDBSCAN with Prioritized Replay
**Effort**: 3 days | **LOC**: +1000

**Files**:
- `src/t4dm/consolidation/replay.py` (NEW)
- `src/t4dm/consolidation/cortical_schema.py` (NEW)
- `src/t4dm/consolidation/service.py` (MODIFY)

```python
# src/t4dm/consolidation/replay.py
"""
Prioritized Experience Replay for Memory Consolidation.

Implements biologically-plausible sleep consolidation via sharp-wave ripple-like
replay of high-value episodic memories.

References:
    - Schaul et al. (2015) "Prioritized Experience Replay"
    - Diekelmann & Born (2010) "The memory function of sleep"
    - Foster & Wilson (2006) "Reverse replay of behavioural sequences"

The key insight is that memories with high temporal-difference error (surprise)
should be replayed more frequently, matching biological observations of
preferential replay of novel and rewarding experiences during sleep.
"""
from dataclasses import dataclass
from typing import Protocol
import numpy as np

@dataclass
class ReplayCandidate:
    """A memory candidate for replay."""
    episode_id: str
    embedding: np.ndarray
    td_error: float
    recency: float
    importance: float
    replay_count: int

class PrioritizedReplay:
    """
    Prioritized replay for memory consolidation.

    Selects episodes for replay proportional to their TD error (surprise),
    with additional factors for recency and importance. Implements
    proportional prioritization with importance sampling correction.

    Args:
        alpha: Priority exponent (0 = uniform, 1 = full prioritization)
        beta: Importance sampling exponent (0 = no correction, 1 = full)
        epsilon: Small constant for numerical stability
    """

    def __init__(
        self,
        alpha: float = 0.6,
        beta: float = 0.4,
        epsilon: float = 1e-6,
    ):
        self.alpha = alpha
        self.beta = beta
        self.epsilon = epsilon

    async def select_replay_candidates(
        self,
        episodes: list[Episode],
        dopamine_history: list[RPERecord],
        n_replay: int = 100,
    ) -> list[ReplayCandidate]:
        """
        Select episodes for replay proportional to TD error.

        Args:
            episodes: All available episodes
            dopamine_history: Recent RPE records from dopamine system
            n_replay: Number of episodes to select for replay

        Returns:
            List of replay candidates with priorities
        """
        # Compute priorities
        priorities = self._compute_priorities(episodes, dopamine_history)

        # Sample proportionally
        probabilities = self._priority_to_probability(priorities)
        indices = np.random.choice(
            len(episodes),
            size=min(n_replay, len(episodes)),
            replace=False,
            p=probabilities,
        )

        # Build candidates with importance sampling weights
        candidates = []
        for idx in indices:
            weight = (len(episodes) * probabilities[idx]) ** (-self.beta)
            candidates.append(ReplayCandidate(
                episode_id=episodes[idx].id,
                embedding=episodes[idx].embedding,
                td_error=priorities[idx],
                recency=self._compute_recency(episodes[idx]),
                importance=episodes[idx].importance,
                replay_count=episodes[idx].replay_count,
            ))

        return candidates

    async def replay_episode(
        self,
        candidate: ReplayCandidate,
        cortical_schema: "CorticalSchema",
        compression_factor: float = 20.0,
    ) -> dict[str, float]:
        """
        Replay an episode to strengthen cortical representation.

        Implements time-compressed replay similar to sharp-wave ripples,
        which occur at ~20x compression during sleep.

        Args:
            candidate: Replay candidate
            cortical_schema: Cortical schema to update
            compression_factor: Time compression (default 20x like SWRs)

        Returns:
            Replay statistics
        """
        # Compress temporal representation
        compressed = await self._compress_sequence(
            candidate.embedding,
            factor=compression_factor,
        )

        # Update cortical schema
        update_stats = await cortical_schema.update(
            compressed,
            learning_rate=candidate.td_error * 0.01,
        )

        return {
            "episode_id": candidate.episode_id,
            "td_error": candidate.td_error,
            "schema_loss": update_stats["loss"],
            "compression_factor": compression_factor,
        }

    def _compute_priorities(
        self,
        episodes: list[Episode],
        dopamine_history: list[RPERecord],
    ) -> np.ndarray:
        """Compute replay priorities from TD errors."""
        # Build episode -> RPE mapping
        rpe_map = {}
        for rpe in dopamine_history:
            if rpe.memory_id not in rpe_map:
                rpe_map[rpe.memory_id] = []
            rpe_map[rpe.memory_id].append(abs(rpe.value))

        # Compute priority for each episode
        priorities = np.zeros(len(episodes))
        for i, ep in enumerate(episodes):
            if ep.id in rpe_map:
                # Use max RPE for this episode
                priorities[i] = max(rpe_map[ep.id])
            else:
                # Default priority for unseen episodes
                priorities[i] = self.epsilon

        return priorities

    def _priority_to_probability(self, priorities: np.ndarray) -> np.ndarray:
        """Convert priorities to sampling probabilities."""
        scaled = (priorities + self.epsilon) ** self.alpha
        return scaled / scaled.sum()
```

```python
# src/t4dm/consolidation/cortical_schema.py
"""
Cortical Schema for Systems Consolidation.

Implements a generative model that learns compressed representations of
episodic memories, representing the gradual transfer from hippocampus
to neocortex during systems consolidation.

References:
    - McClelland et al. (1995) "Why there are complementary learning systems"
    - Kumaran & McClelland (2012) "Generalization through recurrent interaction"
"""
import torch
import torch.nn as nn

class CorticalSchema(nn.Module):
    """
    Cortical schema as a variational autoencoder.

    Learns a compressed latent representation of episodic memories,
    enabling generalization and schema formation.

    Args:
        input_dim: Dimension of episode embeddings
        latent_dim: Dimension of cortical representation
        hidden_dim: Hidden layer dimension
    """

    def __init__(
        self,
        input_dim: int = 1024,
        latent_dim: int = 64,
        hidden_dim: int = 256,
    ):
        super().__init__()

        # Encoder: Episode → Latent
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
        )
        self.fc_mu = nn.Linear(hidden_dim, latent_dim)
        self.fc_var = nn.Linear(hidden_dim, latent_dim)

        # Decoder: Latent → Schema
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim),
        )

    def encode(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:
        """Encode episode to latent distribution."""
        h = self.encoder(x)
        return self.fc_mu(h), self.fc_var(h)

    def reparameterize(self, mu: torch.Tensor, log_var: torch.Tensor) -> torch.Tensor:
        """Reparameterization trick for VAE."""
        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        return mu + eps * std

    def decode(self, z: torch.Tensor) -> torch.Tensor:
        """Decode latent to schema representation."""
        return self.decoder(z)

    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """Forward pass through VAE."""
        mu, log_var = self.encode(x)
        z = self.reparameterize(mu, log_var)
        return self.decode(z), mu, log_var

    async def update(
        self,
        episode_embedding: np.ndarray,
        learning_rate: float = 0.001,
    ) -> dict[str, float]:
        """
        Update schema from replayed episode.

        Args:
            episode_embedding: Compressed episode representation
            learning_rate: Learning rate scaled by TD error

        Returns:
            Update statistics
        """
        x = torch.tensor(episode_embedding, dtype=torch.float32)
        recon, mu, log_var = self(x)

        # VAE loss
        recon_loss = nn.functional.mse_loss(recon, x)
        kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())
        loss = recon_loss + 0.01 * kl_loss

        # Update
        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        return {
            "loss": loss.item(),
            "recon_loss": recon_loss.item(),
            "kl_loss": kl_loss.item(),
        }
```

---

### P1-2: Self-Supervised Credit Signals
**Effort**: 2 days | **LOC**: +700

**File**: `src/t4dm/learning/credit.py`

```python
"""
Self-Supervised Credit Assignment.

Provides continuous learning signals from LLM response patterns without
requiring explicit user feedback. This addresses the credit assignment
bottleneck where eligibility traces decay before outcomes arrive.

Key insight: We can estimate memory utility by analyzing how the LLM
uses retrieved memories in its responses, without waiting for user feedback.

References:
    - Hinton (2022) "The Forward-Forward Algorithm"
    - Jaderberg et al. (2017) "Decoupled Neural Interfaces"
"""
import numpy as np
from dataclasses import dataclass
from typing import Optional
from sentence_transformers import SentenceTransformer

@dataclass
class UtilityEstimate:
    """Estimated utility of a memory retrieval."""
    memory_id: str
    content_reflection: float  # Was content used in response?
    semantic_centrality: float  # How central to response?
    query_relevance: float  # How relevant to original query?
    overall_utility: float  # Combined score
    confidence: float  # Confidence in estimate

class MemoryUtilityEstimator:
    """
    Estimate memory utility from LLM response patterns.

    Provides self-supervised credit signals by analyzing:
    1. Content reflection: Is memory content reflected in response?
    2. Semantic centrality: How central is memory to response meaning?
    3. Query relevance: How well does memory address the query?

    These signals enable continuous learning without explicit feedback.
    """

    def __init__(
        self,
        embedding_model: str = "all-MiniLM-L6-v2",
        reflection_weight: float = 0.4,
        centrality_weight: float = 0.3,
        relevance_weight: float = 0.3,
    ):
        self.encoder = SentenceTransformer(embedding_model)
        self.reflection_weight = reflection_weight
        self.centrality_weight = centrality_weight
        self.relevance_weight = relevance_weight

    async def estimate_utility(
        self,
        query: str,
        retrieved_memories: list["Memory"],
        llm_response: str,
        response_log_probs: Optional[np.ndarray] = None,
    ) -> list[UtilityEstimate]:
        """
        Estimate per-memory utility from LLM response.

        Args:
            query: Original user query
            retrieved_memories: Memories that were retrieved
            llm_response: LLM's response text
            response_log_probs: Optional token log probabilities

        Returns:
            Utility estimates for each memory
        """
        # Encode all texts
        query_emb = self.encoder.encode(query)
        response_emb = self.encoder.encode(llm_response)
        memory_embs = [self.encoder.encode(m.content) for m in retrieved_memories]

        estimates = []
        for i, memory in enumerate(retrieved_memories):
            mem_emb = memory_embs[i]

            # Content reflection: cosine similarity with response
            reflection = self._cosine_similarity(mem_emb, response_emb)

            # Semantic centrality: how much response is about memory content
            centrality = self._compute_centrality(
                mem_emb, response_emb, [e for j, e in enumerate(memory_embs) if j != i]
            )

            # Query relevance: how well memory addresses query
            relevance = self._cosine_similarity(mem_emb, query_emb)

            # Combined utility
            overall = (
                self.reflection_weight * reflection +
                self.centrality_weight * centrality +
                self.relevance_weight * relevance
            )

            # Confidence based on signal agreement
            signals = [reflection, centrality, relevance]
            confidence = 1.0 - np.std(signals)

            estimates.append(UtilityEstimate(
                memory_id=memory.id,
                content_reflection=reflection,
                semantic_centrality=centrality,
                query_relevance=relevance,
                overall_utility=overall,
                confidence=confidence,
            ))

        return estimates

    async def generate_credit_signal(
        self,
        estimates: list[UtilityEstimate],
        dopamine_system: "DopamineSystem",
    ) -> None:
        """
        Generate credit signals from utility estimates.

        Feeds utility estimates back to the dopamine system as implicit
        reward signals, enabling continuous learning.
        """
        for est in estimates:
            # Convert utility to RPE-like signal
            # Positive utility = positive surprise (useful memory)
            # Low utility = negative surprise (not helpful)
            rpe = (est.overall_utility - 0.5) * 2.0 * est.confidence

            await dopamine_system.record_implicit_rpe(
                memory_id=est.memory_id,
                rpe=rpe,
                confidence=est.confidence,
                source="self_supervised",
            )

    def _cosine_similarity(self, a: np.ndarray, b: np.ndarray) -> float:
        """Compute cosine similarity."""
        return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))

    def _compute_centrality(
        self,
        memory_emb: np.ndarray,
        response_emb: np.ndarray,
        other_memory_embs: list[np.ndarray],
    ) -> float:
        """
        Compute how central this memory is to the response.

        A memory is central if the response is more similar to it
        than to other retrieved memories.
        """
        my_sim = self._cosine_similarity(memory_emb, response_emb)

        if not other_memory_embs:
            return my_sim

        other_sims = [
            self._cosine_similarity(other, response_emb)
            for other in other_memory_embs
        ]

        # Centrality = how much better than average
        return (my_sim - np.mean(other_sims)) / (np.std(other_sims) + 1e-6)
```

---

### P1-3: Consolidation-Dopamine Integration
**Effort**: 1 day | **LOC**: +200

**Modify**: `src/t4dm/consolidation/service.py`

```python
# Add to ConsolidationService

async def _get_surprising_episodes(
    self,
    session_id: str,
    threshold: float = 0.3,
) -> list[str]:
    """
    Get episode IDs with high RPE from dopamine system.

    Args:
        session_id: Current session ID
        threshold: Minimum surprise magnitude

    Returns:
        List of episode IDs to prioritize
    """
    from t4dm.learning.dopamine import get_dopamine_system

    dopamine = get_dopamine_system()
    rpe_history = dopamine.get_rpe_history(session_id=session_id)

    surprising = [
        record.memory_id
        for record in rpe_history
        if record.surprise_magnitude > threshold
    ]

    self.logger.info(
        f"Found {len(surprising)} surprising episodes (threshold={threshold})"
    )

    return surprising

async def _consolidate_deep(
    self,
    session_id: str,
    **kwargs,
) -> ConsolidationResult:
    """
    Run deep consolidation with dopamine integration.

    Modified to query dopamine system for surprising memories
    and prioritize them during consolidation.
    """
    # Get surprising episodes from dopamine
    surprising_episodes = await self._get_surprising_episodes(
        session_id,
        threshold=self.config.surprise_threshold,
    )

    if self.config.use_prioritized_replay and surprising_episodes:
        # Use prioritized replay for surprising episodes
        result = await self._consolidate_with_replay(
            session_id,
            priority_episodes=surprising_episodes,
            **kwargs,
        )
    else:
        # Fall back to HDBSCAN clustering
        result = await self._consolidate_with_clustering(
            session_id,
            **kwargs,
        )

    return result
```

---

### P1-4: Learned Neuromodulator Parameters
**Effort**: 2 days | **LOC**: +500

**File**: `src/t4dm/learning/meta_learning.py`

```python
"""
Meta-Learning for Neuromodulator Dynamics.

Implements slow outer-loop learning that adjusts neuromodulator
interaction parameters based on session-level outcomes.

The key insight is that the neuromodulator parameters themselves
should be learnable, not hardcoded. This enables the system to
adapt its learning dynamics to the specific task and user.

References:
    - Finn et al. (2017) "Model-Agnostic Meta-Learning"
    - Duan et al. (2016) "RL²: Fast Reinforcement Learning via Slow RL"
"""
import torch
import torch.nn as nn
from dataclasses import dataclass
from typing import Optional

@dataclass
class SessionOutcome:
    """Outcome metrics for a session."""
    session_id: str
    retrieval_precision: float
    user_satisfaction: float  # 0-1, from explicit feedback
    task_completion: float  # 0-1, estimated
    average_latency: float
    total_retrievals: int
    positive_feedback_ratio: float

class LearnedNeuromodulatorDynamics(nn.Module):
    """
    Meta-learnable neuromodulator parameters.

    Parameters are updated based on session-level outcomes,
    enabling the system to learn optimal neuromodulator dynamics.
    """

    def __init__(
        self,
        meta_lr: float = 0.001,
        param_bounds: Optional[dict] = None,
    ):
        super().__init__()

        # Learnable parameters (initialized to current defaults)
        self.ach_encoding_factor = nn.Parameter(torch.tensor(1.5))
        self.ach_retrieval_factor = nn.Parameter(torch.tensor(0.6))
        self.ne_novelty_threshold = nn.Parameter(torch.tensor(0.3))
        self.ne_exploration_bonus = nn.Parameter(torch.tensor(0.2))
        self.da_learning_rate_scale = nn.Parameter(torch.tensor(1.0))
        self.da_surprise_threshold = nn.Parameter(torch.tensor(0.1))
        self.serotonin_patience_factor = nn.Parameter(torch.tensor(0.8))
        self.serotonin_discount_rate = nn.Parameter(torch.tensor(0.99))

        # Parameter bounds (prevent divergence)
        self.bounds = param_bounds or {
            "ach_encoding_factor": (0.5, 3.0),
            "ach_retrieval_factor": (0.2, 1.0),
            "ne_novelty_threshold": (0.1, 0.8),
            "ne_exploration_bonus": (0.0, 0.5),
            "da_learning_rate_scale": (0.1, 5.0),
            "da_surprise_threshold": (0.01, 0.5),
            "serotonin_patience_factor": (0.3, 1.0),
            "serotonin_discount_rate": (0.9, 0.999),
        }

        self.optimizer = torch.optim.Adam(self.parameters(), lr=meta_lr)
        self.outcome_history: list[SessionOutcome] = []

    def get_params(self) -> dict[str, float]:
        """Get current parameter values."""
        return {
            "ach_encoding_factor": self.ach_encoding_factor.item(),
            "ach_retrieval_factor": self.ach_retrieval_factor.item(),
            "ne_novelty_threshold": self.ne_novelty_threshold.item(),
            "ne_exploration_bonus": self.ne_exploration_bonus.item(),
            "da_learning_rate_scale": self.da_learning_rate_scale.item(),
            "da_surprise_threshold": self.da_surprise_threshold.item(),
            "serotonin_patience_factor": self.serotonin_patience_factor.item(),
            "serotonin_discount_rate": self.serotonin_discount_rate.item(),
        }

    def update_from_session(self, outcome: SessionOutcome) -> dict[str, float]:
        """
        Update parameters based on session outcome.

        Args:
            outcome: Session outcome metrics

        Returns:
            Updated parameter values
        """
        self.outcome_history.append(outcome)

        # Compute meta-loss from outcome
        loss = self._compute_meta_loss(outcome)

        # Update parameters
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()

        # Clamp to bounds
        self._clamp_params()

        return self.get_params()

    def _compute_meta_loss(self, outcome: SessionOutcome) -> torch.Tensor:
        """
        Compute meta-learning loss from session outcome.

        We want to maximize:
        - Retrieval precision
        - User satisfaction
        - Task completion

        And minimize:
        - Latency
        """
        # Weighted combination of outcome metrics
        satisfaction = torch.tensor(outcome.user_satisfaction)
        precision = torch.tensor(outcome.retrieval_precision)
        completion = torch.tensor(outcome.task_completion)

        # We minimize loss, so negate positive metrics
        loss = -(
            0.4 * satisfaction +
            0.3 * precision +
            0.3 * completion
        )

        # Add regularization toward default values
        reg_loss = 0.01 * (
            (self.ach_encoding_factor - 1.5) ** 2 +
            (self.ach_retrieval_factor - 0.6) ** 2 +
            (self.ne_novelty_threshold - 0.3) ** 2 +
            (self.da_learning_rate_scale - 1.0) ** 2
        )

        return loss + reg_loss

    def _clamp_params(self) -> None:
        """Clamp parameters to valid bounds."""
        with torch.no_grad():
            for name, param in self.named_parameters():
                if name in self.bounds:
                    low, high = self.bounds[name]
                    param.clamp_(low, high)

    def save_state(self, path: str) -> None:
        """Save meta-learning state."""
        torch.save({
            "params": self.state_dict(),
            "optimizer": self.optimizer.state_dict(),
            "history": self.outcome_history,
        }, path)

    def load_state(self, path: str) -> None:
        """Load meta-learning state."""
        state = torch.load(path)
        self.load_state_dict(state["params"])
        self.optimizer.load_state_dict(state["optimizer"])
        self.outcome_history = state["history"]
```

---

### P1-5: Fix GABA/Glutamate Role
**Effort**: 1 day | **LOC**: +200, -100

**Modify**: `src/t4dm/neuromodulation/orchestra.py`

Remove GABA/Glutamate from global neuromodulator field.

**Add**: `src/t4dm/memory/lateral_inhibition.py`

```python
"""
Lateral Inhibition for Pattern Separation.

Implements GABA-mediated lateral inhibition as a local circuit mechanism
rather than a global neuromodulatory field. This is biologically accurate:
GABA is a fast ionotropic neurotransmitter (~5ms) that mediates local
inhibition, not a slow diffusive modulator.

References:
    - Douglas & Martin (2004) "Neuronal circuits of the neocortex"
    - Isaacson & Scanziani (2011) "How inhibition shapes cortical activity"
"""
import numpy as np
from typing import Optional

class LateralInhibition:
    """
    Lateral inhibition for winner-take-all competition.

    Implements k-WTA (k-winners-take-all) dynamics that model
    GABA-mediated lateral inhibition in cortical circuits.
    """

    def __init__(
        self,
        ei_balance: float = 0.8,
        inhibition_strength: float = 0.5,
    ):
        """
        Args:
            ei_balance: Excitation/Inhibition ratio (0-1)
            inhibition_strength: Strength of lateral inhibition
        """
        self.ei_balance = ei_balance
        self.inhibition_strength = inhibition_strength

    def apply_kwta(
        self,
        activations: np.ndarray,
        k: int,
        soft: bool = True,
    ) -> np.ndarray:
        """
        Apply k-winners-take-all lateral inhibition.

        Args:
            activations: Input activation pattern
            k: Number of winners to keep active
            soft: If True, use soft inhibition; else hard threshold

        Returns:
            Inhibited activation pattern
        """
        if k >= len(activations):
            return activations

        # Find k-th largest activation
        threshold = np.partition(activations, -k)[-k]

        if soft:
            # Soft inhibition: scale sub-threshold activations
            inhibited = np.where(
                activations >= threshold,
                activations,
                activations * (1 - self.inhibition_strength),
            )
        else:
            # Hard inhibition: zero sub-threshold activations
            inhibited = np.where(activations >= threshold, activations, 0)

        # Apply E/I balance
        return inhibited * self.ei_balance

    def apply_divisive_normalization(
        self,
        activations: np.ndarray,
        sigma: float = 1.0,
    ) -> np.ndarray:
        """
        Apply divisive normalization (gain control).

        Models the normalization observed in cortical circuits,
        where responses are divided by local pool activity.

        Args:
            activations: Input activations
            sigma: Normalization constant

        Returns:
            Normalized activations
        """
        pool_activity = np.sum(activations ** 2)
        return activations / (sigma + np.sqrt(pool_activity))
```

---

### P1-6: Unified State Persistence
**Effort**: 1 day | **LOC**: +400

**File**: `src/t4dm/state.py`

```python
"""
Unified State Persistence for T4DM.

Provides a single interface for saving and loading all learnable
parameters across the system. This enables checkpointing, rollback,
and state transfer between instances.
"""
import json
from dataclasses import dataclass, field, asdict
from datetime import datetime
from pathlib import Path
from typing import Any, Optional
import numpy as np

@dataclass
class T4DMState:
    """
    Complete learnable state of T4DM.

    Captures all parameters that change through learning,
    enabling full state persistence and restoration.
    """

    # Metadata
    version: str = "0.2.0"
    timestamp: str = field(default_factory=lambda: datetime.utcnow().isoformat())
    session_count: int = 0

    # Dopamine system state
    dopamine_state: dict[str, Any] = field(default_factory=dict)

    # Neuromodulator orchestra state
    neuromodulator_state: dict[str, Any] = field(default_factory=dict)

    # Learned memory gate state
    gate_state: dict[str, Any] = field(default_factory=dict)

    # Meta-learning parameters
    meta_params: dict[str, float] = field(default_factory=dict)

    # Cluster index state
    cluster_index_state: dict[str, Any] = field(default_factory=dict)

    # Sparse index state
    sparse_index_state: dict[str, Any] = field(default_factory=dict)

    # Cortical schema state
    cortical_schema_state: dict[str, Any] = field(default_factory=dict)

    # Eligibility trace state
    eligibility_state: dict[str, Any] = field(default_factory=dict)

    # Statistics
    stats: dict[str, Any] = field(default_factory=dict)

    def save(self, path: Path) -> None:
        """
        Save complete state to directory.

        Args:
            path: Directory to save state to
        """
        path = Path(path)
        path.mkdir(parents=True, exist_ok=True)

        # Save manifest
        manifest = {
            "version": self.version,
            "timestamp": self.timestamp,
            "session_count": self.session_count,
            "components": list(self._get_components().keys()),
        }
        with open(path / "manifest.json", "w") as f:
            json.dump(manifest, f, indent=2)

        # Save each component
        for name, state in self._get_components().items():
            self._save_component(path / f"{name}.json", state)

        # Save numpy arrays separately
        if self.cluster_index_state.get("centroids") is not None:
            np.save(
                path / "cluster_centroids.npy",
                self.cluster_index_state["centroids"],
            )

    @classmethod
    def load(cls, path: Path) -> "T4DMState":
        """
        Load complete state from directory.

        Args:
            path: Directory to load state from

        Returns:
            Loaded state
        """
        path = Path(path)

        # Load manifest
        with open(path / "manifest.json") as f:
            manifest = json.load(f)

        # Load each component
        state = cls(
            version=manifest["version"],
            timestamp=manifest["timestamp"],
            session_count=manifest["session_count"],
        )

        for component in manifest["components"]:
            component_path = path / f"{component}.json"
            if component_path.exists():
                with open(component_path) as f:
                    setattr(state, f"{component}_state", json.load(f))

        # Load numpy arrays
        centroids_path = path / "cluster_centroids.npy"
        if centroids_path.exists():
            state.cluster_index_state["centroids"] = np.load(centroids_path)

        return state

    def _get_components(self) -> dict[str, dict]:
        """Get all state components."""
        return {
            "dopamine": self.dopamine_state,
            "neuromodulator": self.neuromodulator_state,
            "gate": self.gate_state,
            "meta": {"params": self.meta_params},
            "cluster_index": self.cluster_index_state,
            "sparse_index": self.sparse_index_state,
            "cortical_schema": self.cortical_schema_state,
            "eligibility": self.eligibility_state,
            "stats": self.stats,
        }

    def _save_component(self, path: Path, state: dict) -> None:
        """Save a single component, handling numpy arrays."""
        # Convert numpy arrays to lists for JSON
        serializable = self._make_serializable(state)
        with open(path, "w") as f:
            json.dump(serializable, f, indent=2)

    def _make_serializable(self, obj: Any) -> Any:
        """Convert numpy arrays to lists for JSON serialization."""
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, dict):
            return {k: self._make_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_serializable(v) for v in obj]
        else:
            return obj


class StateManager:
    """
    Manages state persistence for T4DM.

    Provides high-level operations for checkpointing and restoration.
    """

    def __init__(self, base_path: Path = Path.home() / ".ww" / "state"):
        self.base_path = Path(base_path)
        self.base_path.mkdir(parents=True, exist_ok=True)

    async def checkpoint(
        self,
        name: str = "default",
        ww: "T4DM" = None,
    ) -> Path:
        """
        Create a checkpoint of current state.

        Args:
            name: Checkpoint name
            ww: T4DM instance to checkpoint

        Returns:
            Path to checkpoint
        """
        state = await self._collect_state(ww)
        checkpoint_path = self.base_path / name
        state.save(checkpoint_path)
        return checkpoint_path

    async def restore(
        self,
        name: str = "default",
        ww: "T4DM" = None,
    ) -> T4DMState:
        """
        Restore state from checkpoint.

        Args:
            name: Checkpoint name
            ww: T4DM instance to restore to

        Returns:
            Restored state
        """
        checkpoint_path = self.base_path / name
        state = T4DMState.load(checkpoint_path)
        await self._apply_state(state, ww)
        return state

    def list_checkpoints(self) -> list[dict]:
        """List all available checkpoints."""
        checkpoints = []
        for path in self.base_path.iterdir():
            if path.is_dir() and (path / "manifest.json").exists():
                with open(path / "manifest.json") as f:
                    manifest = json.load(f)
                checkpoints.append({
                    "name": path.name,
                    "timestamp": manifest["timestamp"],
                    "version": manifest["version"],
                    "session_count": manifest["session_count"],
                })
        return sorted(checkpoints, key=lambda x: x["timestamp"], reverse=True)

    async def _collect_state(self, ww: "T4DM") -> T4DMState:
        """Collect state from all components."""
        # Implementation collects from each component
        ...

    async def _apply_state(self, state: T4DMState, ww: "T4DM") -> None:
        """Apply state to all components."""
        # Implementation applies to each component
        ...
```

---

### P1-7: Theta Phase Encoding
**Effort**: 1.5 days | **LOC**: +350

**File**: `src/t4dm/encoding/theta.py`

```python
"""
Theta Phase Encoding for Temporal Context.

Implements theta oscillation (4-8 Hz) phase encoding for temporal
segmentation of episodic memories. In biological systems, theta
oscillations provide a temporal reference frame for encoding and
retrieval, with spike timing within theta cycles encoding position
and temporal context.

References:
    - Hasselmo (2005) "What is the function of hippocampal theta rhythm?"
    - Lisman & Jensen (2013) "The theta-gamma neural code"
    - Buzsáki & Moser (2013) "Memory, navigation and theta rhythm"
"""
import numpy as np
from dataclasses import dataclass
from typing import Optional
import time

@dataclass
class ThetaState:
    """Current state of theta oscillation."""
    phase: float  # 0-1 (0 = trough, 0.5 = peak)
    frequency: float  # Hz
    amplitude: float  # Modulation strength
    cycle_count: int  # Total cycles since start

class ThetaPhaseEncoder:
    """
    Encode temporal context using theta oscillation phase.

    Theta oscillations (~6 Hz) segment continuous experience into
    discrete episodes and provide temporal context for memories.
    Items encoded at similar theta phases are more likely to be
    retrieved together.

    Args:
        theta_freq: Theta frequency in Hz (default 6 Hz)
        phase_bins: Number of phase bins for encoding
        amplitude: Theta modulation amplitude
    """

    def __init__(
        self,
        theta_freq: float = 6.0,
        phase_bins: int = 8,
        amplitude: float = 1.0,
    ):
        self.theta_freq = theta_freq
        self.theta_period = 1.0 / theta_freq
        self.phase_bins = phase_bins
        self.amplitude = amplitude

        # Reference time for phase calculation
        self._start_time = time.time()
        self._cycle_count = 0

    def get_current_phase(self) -> float:
        """
        Get current theta phase (0-1).

        Returns:
            Current phase, where 0 = trough, 0.5 = peak
        """
        elapsed = time.time() - self._start_time
        phase = (elapsed % self.theta_period) / self.theta_period
        return phase

    def get_state(self) -> ThetaState:
        """Get current theta oscillation state."""
        elapsed = time.time() - self._start_time
        return ThetaState(
            phase=self.get_current_phase(),
            frequency=self.theta_freq,
            amplitude=self.amplitude,
            cycle_count=int(elapsed / self.theta_period),
        )

    def encode_phase(
        self,
        embedding: np.ndarray,
        timestamp: Optional[float] = None,
    ) -> np.ndarray:
        """
        Add theta phase encoding to embedding.

        Args:
            embedding: Original embedding vector
            timestamp: Optional timestamp (uses current time if None)

        Returns:
            Embedding with phase encoding appended
        """
        if timestamp is None:
            timestamp = time.time()

        # Compute phase at timestamp
        elapsed = timestamp - self._start_time
        phase = (elapsed % self.theta_period) / self.theta_period

        # Create phase encoding (sin/cos for continuity)
        phase_encoding = self.amplitude * np.array([
            np.sin(2 * np.pi * phase),
            np.cos(2 * np.pi * phase),
        ])

        # Append to embedding
        return np.concatenate([embedding, phase_encoding])

    def encode_phase_binned(
        self,
        embedding: np.ndarray,
        timestamp: Optional[float] = None,
    ) -> np.ndarray:
        """
        Add binned theta phase encoding to embedding.

        Uses discrete phase bins rather than continuous encoding,
        which may be more robust to noise.

        Args:
            embedding: Original embedding vector
            timestamp: Optional timestamp

        Returns:
            Embedding with binned phase encoding appended
        """
        if timestamp is None:
            timestamp = time.time()

        # Compute phase at timestamp
        elapsed = timestamp - self._start_time
        phase = (elapsed % self.theta_period) / self.theta_period

        # Create one-hot phase bin encoding
        bin_idx = int(phase * self.phase_bins) % self.phase_bins
        phase_encoding = np.zeros(self.phase_bins)
        phase_encoding[bin_idx] = self.amplitude

        return np.concatenate([embedding, phase_encoding])

    def compute_phase_similarity(
        self,
        phase1: float,
        phase2: float,
    ) -> float:
        """
        Compute similarity between two theta phases.

        Uses circular distance to handle phase wraparound.

        Args:
            phase1: First phase (0-1)
            phase2: Second phase (0-1)

        Returns:
            Similarity (1 = same phase, 0 = opposite phase)
        """
        # Circular distance
        diff = abs(phase1 - phase2)
        circular_diff = min(diff, 1 - diff)

        # Convert to similarity (0-1)
        return 1 - (circular_diff * 2)

    def get_phase_neighbors(
        self,
        target_phase: float,
        all_phases: np.ndarray,
        n_neighbors: int = 5,
    ) -> np.ndarray:
        """
        Find memories with similar theta phase.

        Args:
            target_phase: Target phase to match
            all_phases: Array of all memory phases
            n_neighbors: Number of neighbors to return

        Returns:
            Indices of phase neighbors
        """
        similarities = np.array([
            self.compute_phase_similarity(target_phase, p)
            for p in all_phases
        ])
        return np.argsort(similarities)[-n_neighbors:][::-1]
```

---

### P1-8: Documentation
**Effort**: 2 days | **LOC**: +3000 (docs)

See [Documentation Requirements](#documentation-requirements) section.

---

## P2: Medium Priority

### P2-1: Contrastive Eligibility Traces
**Effort**: 2 days | **LOC**: +500

**File**: `src/t4dm/learning/contrastive_eligibility.py`

Track memories that were retrieved together vs competed, enabling learning from relative usefulness.

---

### P2-2: Regional Neuromodulator Dynamics
**Effort**: 3 days | **LOC**: +800

**File**: `src/t4dm/neuromodulation/regional.py`

Separate VTA-DA (reward) from SNc-DA (motor), basal forebrain ACh from cortical ACh.

---

### P2-3: CLI Utility Commands
**Effort**: 1 day | **LOC**: +200

Add `ww tune`, `ww introspect`, `ww metrics` commands.

---

### P2-4: Graceful Dependency Handling
**Effort**: 0.5 days | **LOC**: +100

Helpful errors when Neo4j/Qdrant not running.

---

### P2-5: Scientific Citations
**Effort**: 0.5 days | **LOC**: +200

Add citations to module docstrings, create CITATION.cff.

---

## P3: Advanced Features

### P3-1: Embedded Backends (SQLite + Faiss)
**Effort**: 5 days | **LOC**: +1500

**Files**:
- `src/t4dm/storage/backends/sqlite_graph.py`
- `src/t4dm/storage/backends/faiss_vector.py`

Zero-config installation without external databases.

---

### P3-2: End-to-End Differentiable RL
**Effort**: 5 days | **LOC**: +1000

**Files**:
- `src/t4dm/learning/dpo.py` - Direct Preference Optimization
- `src/t4dm/learning/grpo.py` - Group Relative Policy Optimization
- `src/t4dm/learning/lora_adapter.py` - LoRA for embedding model

---

### P3-3: Entorhinal Cortex / Place Cells
**Effort**: 3 days | **LOC**: +600

**File**: `src/t4dm/encoding/spatial.py`

Grid cell encoding, successor representation for spatial context.

---

### P3-4: Amygdala Emotional Modulation
**Effort**: 2 days | **LOC**: +400

**File**: `src/t4dm/neuromodulation/amygdala.py`

Valence detection, emotional arousal enhances consolidation.

---

### P3-5: Systems Consolidation with VAE
**Effort**: 3 days | **LOC**: +500

**File**: `src/t4dm/consolidation/systems_consolidation.py`

Train VAE on replayed episodes, gradual hippocampal → cortical transfer.

---

## Testing Requirements

### Test Coverage Targets

| Module | Current | Target | Priority |
|--------|---------|--------|----------|
| `t4dm.cli` | 0% | 95% | P0 |
| `ww.config` | 0% | 95% | P0 |
| `t4dm.api` | 0% | 95% | P0 |
| `t4dm.consolidation.replay` | 0% | 90% | P1 |
| `t4dm.consolidation.cortical_schema` | 0% | 85% | P1 |
| `t4dm.learning.credit` | 0% | 90% | P1 |
| `t4dm.learning.meta_learning` | 0% | 85% | P1 |
| `t4dm.memory.lateral_inhibition` | 0% | 90% | P1 |
| `ww.state` | 0% | 95% | P1 |
| `t4dm.encoding.theta` | 0% | 90% | P1 |
| **Overall** | 80% | 90% | - |

### New Test Files

```
tests/
├── unit/
│   ├── test_cli.py                    # 40+ tests
│   ├── test_config.py                 # 25+ tests
│   ├── test_api.py                    # 30+ tests
│   ├── test_replay.py                 # 25+ tests
│   ├── test_cortical_schema.py        # 20+ tests
│   ├── test_credit.py                 # 25+ tests
│   ├── test_meta_learning.py          # 20+ tests
│   ├── test_lateral_inhibition.py     # 15+ tests
│   ├── test_state.py                  # 25+ tests
│   ├── test_theta.py                  # 20+ tests
│   └── test_embedded_backends.py      # 30+ tests (P3)
├── integration/
│   ├── test_cli_integration.py        # 20+ tests
│   ├── test_api_integration.py        # 25+ tests
│   ├── test_consolidation_integration.py  # 15+ tests
│   └── test_end_to_end.py             # 20+ tests
├── performance/
│   ├── test_replay_benchmarks.py      # 10+ tests
│   ├── test_credit_benchmarks.py      # 10+ tests
│   └── test_api_benchmarks.py         # 15+ tests
└── property/
    ├── test_api_properties.py         # Hypothesis tests
    ├── test_state_properties.py       # Hypothesis tests
    └── test_encoding_properties.py    # Hypothesis tests
```

### Test Examples

```python
# tests/unit/test_cli.py
"""CLI unit tests."""
import pytest
from typer.testing import CliRunner
from t4dm.cli import app

runner = CliRunner()

class TestInit:
    def test_init_creates_config_dir(self, tmp_path):
        result = runner.invoke(app, ["init", "--path", str(tmp_path / ".ww")])
        assert result.exit_code == 0
        assert (tmp_path / ".ww" / "config.yaml").exists()

    def test_init_force_overwrites(self, tmp_path):
        config_dir = tmp_path / ".ww"
        config_dir.mkdir()
        (config_dir / "config.yaml").write_text("old: config")

        result = runner.invoke(app, ["init", "--path", str(config_dir), "--force"])
        assert result.exit_code == 0
        assert "old" not in (config_dir / "config.yaml").read_text()

class TestStore:
    def test_store_returns_id(self, ww_client):
        result = runner.invoke(app, ["store", "Test memory"])
        assert result.exit_code == 0
        assert "id:" in result.output

    def test_store_with_tags(self, ww_client):
        result = runner.invoke(app, ["store", "Test", "--tags", "a", "--tags", "b"])
        assert result.exit_code == 0

class TestRecall:
    def test_recall_returns_results(self, ww_client):
        runner.invoke(app, ["store", "Python is a programming language"])
        result = runner.invoke(app, ["recall", "programming"])
        assert result.exit_code == 0
        assert "Python" in result.output

    def test_recall_json_format(self, ww_client):
        result = runner.invoke(app, ["recall", "test", "--format", "json"])
        assert result.exit_code == 0
        import json
        json.loads(result.output)  # Should not raise

class TestDoctor:
    def test_doctor_checks_neo4j(self, ww_client):
        result = runner.invoke(app, ["doctor"])
        assert "neo4j" in result.output.lower()

    def test_doctor_checks_qdrant(self, ww_client):
        result = runner.invoke(app, ["doctor"])
        assert "qdrant" in result.output.lower()
```

```python
# tests/integration/test_end_to_end.py
"""End-to-end integration tests."""
import pytest
from ww import memory, T4DM

@pytest.mark.integration
class TestEndToEnd:
    async def test_full_workflow(self, ww_instance):
        """Test complete store → recall → consolidate → recall workflow."""
        # Store memories
        id1 = await memory.astore("Python was created by Guido van Rossum")
        id2 = await memory.astore("JavaScript was created by Brendan Eich")
        id3 = await memory.astore("Rust was created by Graydon Hoare")

        # Recall
        results = await memory.arecall("Who created Python?")
        assert len(results) > 0
        assert any("Guido" in r.content for r in results)

        # Provide feedback
        await memory.afeedback(id1, positive=True, magnitude=1.0)

        # Consolidate
        stats = await memory.aconsolidate()
        assert stats["episodes_processed"] > 0

        # Recall again (should be improved)
        results2 = await memory.arecall("Who created Python?")
        assert results2[0].score >= results[0].score

    async def test_learning_improves_recall(self, ww_instance):
        """Test that learning signals improve future recall."""
        # Initial state
        state1 = await memory.aintrospect()

        # Store and get positive feedback
        for i in range(10):
            id = await memory.astore(f"Test memory {i}")
            await memory.afeedback(id, positive=True)

        # Consolidate
        await memory.aconsolidate(full=True)

        # Check learning state changed
        state2 = await memory.aintrospect()
        assert state2.session_count > state1.session_count
```

---

## Documentation Requirements

### Structure

```
docs/
├── index.md                    # Home page
├── quickstart.md               # 5-minute getting started
├── installation.md             # Detailed installation
├── configuration.md            # Configuration reference
├── api/
│   ├── index.md               # API overview
│   ├── simple.md              # Simple API (from ww import memory)
│   ├── advanced.md            # Advanced API (T4DM class)
│   ├── cli.md                 # CLI reference
│   └── rest.md                # REST API reference
├── concepts/
│   ├── architecture.md        # System architecture
│   ├── memory-types.md        # Episodic, semantic, procedural
│   ├── neuromodulation.md     # Neuromodulator system
│   ├── consolidation.md       # Sleep consolidation
│   └── learning.md            # Learning and credit assignment
├── biology/
│   ├── index.md               # Neuroscience background
│   ├── references.md          # Scientific references
│   └── validity.md            # Biological validity assessment
├── guides/
│   ├── kymera-integration.md  # Integrating with Kymera
│   ├── ccflow-integration.md  # Integrating with cc-flow
│   ├── custom-backends.md     # Creating custom backends
│   └── tuning.md              # Performance tuning
├── examples/
│   ├── basic.md               # Basic usage examples
│   ├── async.md               # Async usage
│   ├── cli.md                 # CLI examples
│   └── advanced.md            # Advanced patterns
├── development/
│   ├── contributing.md        # Contribution guide
│   ├── testing.md             # Testing guide
│   ├── architecture.md        # Internal architecture
│   └── changelog.md           # Version history
└── llm/
    ├── context.md             # LLM-friendly context summary
    ├── api-cheatsheet.md      # Quick API reference for LLMs
    └── prompts.md             # Example prompts for LLM integration
```

### LLM-Friendly Documentation

**File**: `docs/llm/context.md`

```markdown
# T4DM - LLM Context Summary

## What is T4DM?

T4DM is a biologically-inspired memory system for AI agents.
It provides persistent, learnable memory with:
- Episodic memory (experiences)
- Semantic memory (facts/concepts)
- Procedural memory (skills)
- Neuromodulation (dopamine, acetylcholine, etc.)
- Sleep consolidation (memory optimization)

## Quick API

```python
from ww import memory

# Store a memory
memory.store("The user prefers dark mode", tags=["preference"])

# Recall memories
results = memory.recall("user preferences", k=5)
for r in results:
    print(f"{r.content} (score: {r.score:.2f})")

# Provide feedback
memory.feedback(results[0].id, positive=True)

# Run consolidation
memory.consolidate()

# Check learning state
state = memory.introspect()
print(f"Dopamine: {state.dopamine_level:.2f}")
```

## Key Concepts

- **Episodes**: Individual experiences with context and timestamp
- **Concepts**: Semantic entities with relationships
- **Skills**: Procedural knowledge as step sequences
- **RPE**: Reward Prediction Error - drives learning
- **Consolidation**: Sleep-like optimization of memories

## Common Patterns

### Store user context
```python
memory.store(f"User is working on {project}", context={"source": "observation"})
```

### Recall relevant context
```python
results = memory.recall(user_query, k=10)
context = "\n".join(r.content for r in results if r.score > 0.5)
```

### Learn from feedback
```python
if user_liked_response:
    for mem_id in used_memories:
        memory.feedback(mem_id, positive=True)
```

## Integration Points

- **REST API**: `http://localhost:8420/api/v1/`
- **Python SDK**: `from ww import memory`
- **CLI**: `t4dm store`, `t4dm recall`, `t4dm consolidate`

## For More

See full documentation at: https://t4dm.readthedocs.io
```

**File**: `docs/llm/api-cheatsheet.md`

```markdown
# T4DM API Cheatsheet

## Simple API

| Function | Description | Example |
|----------|-------------|---------|
| `store(content, tags=[], importance=0.5)` | Store episode | `memory.store("fact", tags=["a"])` |
| `recall(query, k=5)` | Recall memories | `memory.recall("query")` |
| `consolidate(full=False)` | Run sleep cycle | `memory.consolidate()` |
| `introspect()` | Get learning state | `memory.introspect()` |
| `feedback(id, positive, magnitude=1.0)` | Provide feedback | `memory.feedback(id, True)` |

## Async API

Same functions with `a` prefix: `astore`, `arecall`, `aconsolidate`, etc.

## CLI

```bash
ww init                 # Initialize
ww store "content"      # Store
ww recall "query"       # Recall
t4dm consolidate          # Consolidate
ww status              # Status
ww doctor              # Health check
```

## REST API

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/episodes` | POST | Store episode |
| `/api/v1/episodes/recall` | POST | Recall episodes |
| `/api/v1/consolidate` | POST | Run consolidation |
| `/api/v1/feedback` | POST | Provide feedback |
| `/api/v1/status` | GET | Get status |
| `/health` | GET | Health check |
| `/docs` | GET | OpenAPI docs |
```

---

## Examples

### Directory Structure

```
examples/
├── 01_basic_usage.py          # Simple store/recall
├── 02_async_usage.py          # Async patterns
├── 03_with_feedback.py        # Learning from feedback
├── 04_consolidation.py        # Sleep consolidation
├── 05_cli_usage.sh            # CLI examples
├── 06_rest_api.py             # REST API client
├── 07_kymera_integration.py   # Kymera integration
├── 08_ccflow_skill.py         # cc-flow skill
├── 09_custom_config.py        # Custom configuration
├── 10_state_management.py     # Checkpoints and restore
└── notebooks/
    ├── quickstart.ipynb       # Interactive quickstart
    ├── learning_demo.ipynb    # Learning visualization
    └── architecture.ipynb     # Architecture exploration
```

### Example: Basic Usage

```python
#!/usr/bin/env python3
"""
T4DM - Basic Usage Example

This example demonstrates the core functionality:
1. Storing memories
2. Recalling memories
3. Providing feedback
4. Running consolidation
"""
from ww import memory

def main():
    # Store some memories
    print("Storing memories...")

    memory.store(
        "Python was created by Guido van Rossum in 1991",
        tags=["programming", "history"],
        importance=0.8,
    )

    memory.store(
        "JavaScript was created by Brendan Eich in 1995",
        tags=["programming", "history"],
        importance=0.7,
    )

    memory.store(
        "The user prefers dark mode interfaces",
        tags=["preferences"],
        importance=0.9,
    )

    # Recall memories
    print("\nRecalling programming-related memories...")
    results = memory.recall("programming languages", k=5)

    for i, result in enumerate(results, 1):
        print(f"  {i}. {result.content}")
        print(f"     Score: {result.score:.3f}, Type: {result.memory_type}")

    # Provide feedback on useful memories
    if results:
        print(f"\nProviding positive feedback on top result...")
        memory.feedback(results[0].id, positive=True, magnitude=1.0)

    # Check learning state
    print("\nCurrent learning state:")
    state = memory.introspect()
    print(f"  Dopamine level: {state.dopamine_level:.3f}")
    print(f"  ACh mode: {state.acetylcholine_mode}")
    print(f"  Total episodes: {state.total_episodes}")

    # Run consolidation
    print("\nRunning consolidation...")
    stats = memory.consolidate()
    print(f"  Episodes processed: {stats.get('episodes_processed', 0)}")
    print(f"  Clusters formed: {stats.get('clusters_formed', 0)}")

    print("\nDone!")

if __name__ == "__main__":
    main()
```

### Example: cc-flow Integration

```python
#!/usr/bin/env python3
"""
T4DM - cc-flow Skill Integration

This skill provides T4DM memory access from Claude Code.

Install:
    cp examples/08_ccflow_skill.py ~/.claude/skills/ww_memory.py

Usage in Claude Code:
    /ww-store "content" --tags tag1,tag2
    /ww-recall "query" --k 5
    /ww-consolidate
"""
from ww import memory
from t4dm.api import RecallResult

# Skill metadata
SKILL_NAME = "ww-memory"
SKILL_DESCRIPTION = "T4DM memory integration for Claude Code"

async def ww_store(
    content: str,
    tags: list[str] | None = None,
    importance: float = 0.5,
) -> dict:
    """
    Store a memory in T4DM.

    Args:
        content: Content to store
        tags: Optional tags for categorization
        importance: Importance score 0-1

    Returns:
        {"id": str, "success": bool}
    """
    episode_id = await memory.astore(
        content,
        tags=tags or [],
        importance=importance,
    )
    return {"id": episode_id, "success": True}

async def ww_recall(
    query: str,
    k: int = 5,
    min_score: float = 0.0,
) -> list[dict]:
    """
    Recall memories from T4DM.

    Args:
        query: Search query
        k: Number of results
        min_score: Minimum similarity score

    Returns:
        List of memory results
    """
    results = await memory.arecall(query, k=k, min_score=min_score)
    return [
        {
            "id": r.id,
            "content": r.content,
            "score": r.score,
            "type": r.memory_type,
        }
        for r in results
    ]

async def ww_feedback(
    memory_id: str,
    positive: bool,
    magnitude: float = 1.0,
) -> dict:
    """
    Provide feedback on a memory retrieval.

    Args:
        memory_id: ID of the memory
        positive: Whether feedback is positive
        magnitude: Strength of feedback

    Returns:
        {"success": bool}
    """
    await memory.afeedback(memory_id, positive=positive, magnitude=magnitude)
    return {"success": True}

async def ww_consolidate(full: bool = False) -> dict:
    """
    Run memory consolidation.

    Args:
        full: Whether to run full consolidation

    Returns:
        Consolidation statistics
    """
    stats = await memory.aconsolidate(full=full)
    return stats

async def ww_introspect() -> dict:
    """
    Get current learning state.

    Returns:
        Learning state information
    """
    state = await memory.aintrospect()
    return {
        "dopamine_level": state.dopamine_level,
        "acetylcholine_mode": state.acetylcholine_mode,
        "norepinephrine_level": state.norepinephrine_level,
        "total_episodes": state.total_episodes,
        "total_concepts": state.total_concepts,
    }
```

---

## Security

### Security Checklist

- [ ] **Input Validation**: All user inputs validated
- [ ] **SQL/Cypher Injection**: Parameterized queries only
- [ ] **Path Traversal**: Validate all file paths
- [ ] **Secrets Management**: No hardcoded secrets
- [ ] **Dependency Audit**: All deps scanned for vulnerabilities
- [ ] **Rate Limiting**: API rate limits enforced
- [ ] **Authentication**: Optional API key auth
- [ ] **CORS**: Configurable CORS policy
- [ ] **TLS**: HTTPS support documented
- [ ] **Logging**: No sensitive data in logs

### Security Policy

**File**: `SECURITY.md`

```markdown
# Security Policy

## Supported Versions

| Version | Supported          |
| ------- | ------------------ |
| 0.2.x   | :white_check_mark: |
| < 0.2   | :x:                |

## Reporting a Vulnerability

Please report security vulnerabilities to: security@example.com

Do NOT open public issues for security vulnerabilities.

We will respond within 48 hours and work with you to understand
and address the issue.

## Security Best Practices

### API Keys

Never commit API keys or secrets. Use environment variables:

```bash
export T4DM_NEO4J__PASSWORD="your-password"
```

### Network Security

In production, always:
1. Use TLS for all connections
2. Restrict network access to Neo4j/Qdrant
3. Enable authentication on all services

### Data Privacy

T4DM stores user data. Ensure:
1. Compliance with applicable data protection laws
2. Proper data retention policies
3. Secure backup procedures
```

---

## API Documentation Endpoint

### REST API with OpenAPI

**File**: `src/t4dm/api/server.py`

```python
"""
T4DM REST API Server.

Provides REST API access to T4DM with automatic OpenAPI documentation.
"""
from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import RedirectResponse
from pydantic import BaseModel, Field
from typing import Any, Optional
import uvicorn

from ww import __version__
from t4dm.config import WWConfig

# API Models
class StoreRequest(BaseModel):
    """Request to store an episode."""
    content: str = Field(..., description="Content to store")
    tags: list[str] = Field(default=[], description="Tags for categorization")
    importance: float = Field(default=0.5, ge=0, le=1, description="Importance score")
    context: dict[str, Any] = Field(default={}, description="Additional context")

class StoreResponse(BaseModel):
    """Response from store operation."""
    id: str = Field(..., description="Episode ID")
    success: bool = Field(default=True)

class RecallRequest(BaseModel):
    """Request to recall memories."""
    query: str = Field(..., description="Search query")
    k: int = Field(default=5, ge=1, le=100, description="Number of results")
    memory_type: str = Field(default="all", description="episodic|semantic|procedural|all")
    min_score: float = Field(default=0.0, ge=0, le=1, description="Minimum score")

class RecallResult(BaseModel):
    """Single recall result."""
    id: str
    content: str
    score: float
    memory_type: str
    metadata: dict[str, Any]
    created_at: str

class RecallResponse(BaseModel):
    """Response from recall operation."""
    results: list[RecallResult]
    query: str
    total: int

class FeedbackRequest(BaseModel):
    """Request to provide feedback."""
    memory_id: str = Field(..., description="Memory ID")
    positive: bool = Field(..., description="Whether feedback is positive")
    magnitude: float = Field(default=1.0, ge=0, le=1, description="Feedback strength")

class ConsolidateRequest(BaseModel):
    """Request to run consolidation."""
    full: bool = Field(default=False, description="Run full consolidation")

class ConsolidateResponse(BaseModel):
    """Response from consolidation."""
    episodes_processed: int
    clusters_formed: int
    memories_pruned: int
    duration_seconds: float

class IntrospectResponse(BaseModel):
    """Learning state response."""
    dopamine_level: float
    acetylcholine_mode: str
    norepinephrine_level: float
    serotonin_level: float
    total_episodes: int
    total_concepts: int
    total_skills: int

class HealthResponse(BaseModel):
    """Health check response."""
    status: str
    version: str
    neo4j: str
    qdrant: str

# Create app
def create_app(config: WWConfig | None = None) -> FastAPI:
    """Create FastAPI application."""
    config = config or WWConfig.load()

    app = FastAPI(
        title="T4DM API",
        description="""
# T4DM REST API

Biologically-inspired memory system for AI agents.

## Features

- **Episodic Memory**: Store and recall experiences
- **Semantic Memory**: Facts and concepts with relationships
- **Procedural Memory**: Skills and procedures
- **Neuromodulation**: Dopamine, acetylcholine, etc.
- **Sleep Consolidation**: Memory optimization

## Quick Start

```python
import httpx

client = httpx.Client(base_url="http://localhost:8420")

# Store
resp = client.post("/api/v1/episodes", json={"content": "Hello world"})
episode_id = resp.json()["id"]

# Recall
resp = client.post("/api/v1/episodes/recall", json={"query": "hello"})
results = resp.json()["results"]
```
        """,
        version=__version__,
        docs_url="/docs",
        redoc_url="/redoc",
        openapi_url="/openapi.json",
    )

    # CORS
    app.add_middleware(
        CORSMiddleware,
        allow_origins=config.api.cors_origins,
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    # Routes
    @app.get("/", include_in_schema=False)
    async def root():
        """Redirect to docs."""
        return RedirectResponse(url="/docs")

    @app.get("/health", response_model=HealthResponse, tags=["System"])
    async def health():
        """Health check endpoint."""
        # Check backends
        neo4j_status = await check_neo4j()
        qdrant_status = await check_qdrant()

        return HealthResponse(
            status="healthy" if neo4j_status == "ok" and qdrant_status == "ok" else "degraded",
            version=__version__,
            neo4j=neo4j_status,
            qdrant=qdrant_status,
        )

    @app.post("/api/v1/episodes", response_model=StoreResponse, tags=["Episodes"])
    async def store_episode(request: StoreRequest):
        """Store an episode in memory."""
        from ww import memory
        episode_id = await memory.astore(
            request.content,
            tags=request.tags,
            importance=request.importance,
            context=request.context,
        )
        return StoreResponse(id=episode_id)

    @app.post("/api/v1/episodes/recall", response_model=RecallResponse, tags=["Episodes"])
    async def recall_episodes(request: RecallRequest):
        """Recall episodes matching query."""
        from ww import memory
        results = await memory.arecall(
            request.query,
            k=request.k,
            memory_type=request.memory_type,
            min_score=request.min_score,
        )
        return RecallResponse(
            results=[
                RecallResult(
                    id=r.id,
                    content=r.content,
                    score=r.score,
                    memory_type=r.memory_type,
                    metadata=r.metadata,
                    created_at=r.created_at,
                )
                for r in results
            ],
            query=request.query,
            total=len(results),
        )

    @app.post("/api/v1/feedback", tags=["Learning"])
    async def provide_feedback(request: FeedbackRequest):
        """Provide feedback on a memory retrieval."""
        from ww import memory
        await memory.afeedback(
            request.memory_id,
            positive=request.positive,
            magnitude=request.magnitude,
        )
        return {"success": True}

    @app.post("/api/v1/consolidate", response_model=ConsolidateResponse, tags=["Learning"])
    async def consolidate(request: ConsolidateRequest):
        """Run memory consolidation."""
        from ww import memory
        stats = await memory.aconsolidate(full=request.full)
        return ConsolidateResponse(**stats)

    @app.get("/api/v1/introspect", response_model=IntrospectResponse, tags=["Learning"])
    async def introspect():
        """Get current learning state."""
        from ww import memory
        state = await memory.aintrospect()
        return IntrospectResponse(
            dopamine_level=state.dopamine_level,
            acetylcholine_mode=state.acetylcholine_mode,
            norepinephrine_level=state.norepinephrine_level,
            serotonin_level=state.serotonin_level,
            total_episodes=state.total_episodes,
            total_concepts=state.total_concepts,
            total_skills=state.total_skills,
        )

    return app

def run_server(
    host: str = "0.0.0.0",
    port: int = 8420,
    reload: bool = False,
):
    """Run the API server."""
    app = create_app()
    uvicorn.run(app, host=host, port=port, reload=reload)

if __name__ == "__main__":
    run_server()
```

---

## Release Artifacts

### Files to Create/Update

| File | Status | Description |
|------|--------|-------------|
| `README.md` | Update | Complete rewrite |
| `LICENSE` | Create | MIT License |
| `CHANGELOG.md` | Update | v0.2.0 changes |
| `SECURITY.md` | Create | Security policy |
| `CONTRIBUTING.md` | Create | Contribution guide |
| `CITATION.cff` | Create | Citation file |
| `pyproject.toml` | Update | Package config |
| `.github/workflows/` | Create | CI/CD |
| `docs/` | Create | Full documentation |
| `examples/` | Create | 10+ examples |

### README.md Template

```markdown
# T4DM

[![PyPI version](https://badge.fury.io/py/t4dm.svg)](https://badge.fury.io/py/t4dm)
[![Tests](https://github.com/astoreyai/t4dm/actions/workflows/tests.yml/badge.svg)](https://github.com/astoreyai/t4dm/actions/workflows/tests.yml)
[![Coverage](https://codecov.io/gh/astoreyai/t4dm/branch/main/graph/badge.svg)](https://codecov.io/gh/astoreyai/t4dm)
[![Documentation](https://readthedocs.org/projects/t4dm/badge/?version=latest)](https://t4dm.readthedocs.io)

**Biologically-inspired memory system for AI agents.**

T4DM provides persistent, learnable memory with neuromodulation,
sleep consolidation, and continuous learning from feedback.

## Features

- **Tripartite Memory**: Episodic, semantic, and procedural memory
- **Neuromodulation**: Dopamine, acetylcholine, norepinephrine, serotonin
- **Sleep Consolidation**: Biologically-plausible memory optimization
- **Continuous Learning**: Learn from implicit and explicit feedback
- **Simple API**: `from ww import memory`

## Quick Start

```bash
pip install t4dm[production]
ww init
ww infra up  # Start Neo4j + Qdrant
```

```python
from ww import memory

# Store
memory.store("Python was created in 1991", tags=["programming"])

# Recall
results = memory.recall("When was Python created?")
print(results[0].content)  # Python was created in 1991

# Learn
memory.feedback(results[0].id, positive=True)

# Consolidate
memory.consolidate()
```

## Documentation

- [Quickstart](https://t4dm.readthedocs.io/quickstart)
- [API Reference](https://t4dm.readthedocs.io/api)
- [Architecture](https://t4dm.readthedocs.io/architecture)
- [Examples](https://github.com/astoreyai/t4dm/tree/main/examples)

## License

MIT License - see [LICENSE](LICENSE)

## Citation

```bibtex
@software{t4dm,
  author = {Storey, Aaron},
  title = {T4DM: Biologically-inspired Memory for AI},
  year = {2026},
  url = {https://github.com/astoreyai/t4dm}
}
```
```

---

## Summary

### Total Effort

| Category | Effort |
|----------|--------|
| P0: Critical | 5 days |
| P1: High Priority | 13.5 days |
| P2: Medium Priority | 7 days |
| P3: Advanced | 15 days |
| Testing | 5 days |
| Documentation | 5 days |
| Examples | 3 days |
| Security | 2 days |
| **Total** | **~55 days** |

### Deliverables

- [ ] PyPI package: `pip install t4dm`
- [ ] CLI: `ww` command with 15+ subcommands
- [ ] REST API: `/docs` endpoint with OpenAPI
- [ ] Python SDK: Simple and advanced APIs
- [ ] Documentation: Full MkDocs site
- [ ] Examples: 10+ working examples
- [ ] Tests: 90%+ coverage, 400+ new tests
- [ ] Security: Audit complete, SECURITY.md

---

*Document created: 2026-01-02*
*Last updated: 2026-01-02*
