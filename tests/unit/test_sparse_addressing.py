"""
Tests for learned sparse addressing mechanism.

Biologically-grounded validation of:
1. Sparsity levels under different loads
2. Addressing accuracy (correct memory selection)
3. Interference resistance (similar memories don't collide)

Biological References:
- DG granule cells: ~2% active sparsity, 10:1 expansion ratio
- Sparse coding benefits: reduced interference, increased capacity
- Hippocampal indexing: sparse distributed representations
"""

import asyncio
import numpy as np
import pytest
import pytest_asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Set
from uuid import uuid4

from ww.core.learned_gate import LearnedMemoryGate, GateDecision
from ww.core.memory_gate import GateContext, StorageDecision
from ww.learning.neuromodulators import NeuromodulatorState


# =============================================================================
# Biological Constants
# =============================================================================

# Dentate Gyrus sparse coding
TARGET_SPARSITY = 0.02  # ~2% of neurons active
SPARSITY_TOLERANCE = 0.01  # Allow Â±1% variation

# Expansion ratio (input to DG)
DG_EXPANSION_RATIO = 10

# Interference threshold (overlap in sparse codes)
MAX_INTERFERENCE = 0.15  # < 15% overlap for distinct memories


# =============================================================================
# 1. Sparsity Level Tests
# =============================================================================

class TestSparsityLevels:
    """
    Test that sparse addressing maintains appropriate sparsity levels.

    Biology: DG maintains ~2% activation sparsity across varying
    input loads to maximize pattern separation.
    """

    @pytest.fixture
    def gate(self):
        """Create learned gate for testing."""
        return LearnedMemoryGate(
            neuromod_orchestra=None,
            cold_start_threshold=10,
            use_diagonal_covariance=True
        )

    @pytest.fixture
    def neuromod_state(self):
        """Create neuromodulator state."""
        return NeuromodulatorState(
            dopamine_rpe=0.0,
            norepinephrine_gain=1.0,
            acetylcholine_mode="balanced",
            serotonin_mood=0.5,
            inhibition_sparsity=0.3
        )

    def compute_activation_sparsity(self, activations: np.ndarray,
                                   threshold: float = 0.5) -> float:
        """
        Compute sparsity of activation pattern.

        Returns proportion of units above threshold.
        """
        active = np.sum(activations > threshold)
        total = len(activations)
        return active / total

    def test_low_load_sparsity(self, gate, neuromod_state):
        """
        Test sparsity under low input load.

        Biology: DG maintains consistent sparsity even with few inputs.
        """
        # Create context
        context = GateContext(
            session_id="test-session",
            project="ww",
            current_task="testing",
            last_store_time=datetime.now() - timedelta(minutes=5),
            message_count_since_store=2
        )

        # Generate small batch of inputs
        n_inputs = 10
        decisions = []

        for i in range(n_inputs):
            embedding = np.random.randn(1024).astype(np.float32)
            decision = gate.predict(embedding, context, neuromod_state, explore=False)
            decisions.append(decision)

        # Compute effective sparsity from decisions
        # (proportion of STORE decisions represents active selections)
        store_count = sum(1 for d in decisions if d.action == StorageDecision.STORE)
        sparsity = store_count / n_inputs

        # Under low load, gate should be selective (sparse)
        # Allow broader tolerance for small samples
        assert 0.0 <= sparsity <= 0.5, (
            f"Low-load sparsity {sparsity:.3f} too high (should be selective)"
        )

    def test_high_load_sparsity(self, gate, neuromod_state):
        """
        Test sparsity under high input load.

        Biology: DG maintains sparsity via competitive inhibition
        even under high input loads.
        """
        context = GateContext(
            session_id="test-session",
            project="ww",
            current_task="testing",
            last_store_time=datetime.now() - timedelta(minutes=1),
            message_count_since_store=10  # High load
        )

        # Generate large batch
        n_inputs = 100
        decisions = []

        for i in range(n_inputs):
            embedding = np.random.randn(1024).astype(np.float32)
            decision = gate.predict(embedding, context, neuromod_state, explore=False)
            decisions.append(decision)

        # Measure sparsity
        store_count = sum(1 for d in decisions if d.action == StorageDecision.STORE)
        sparsity = store_count / n_inputs

        # Should maintain sparse selection even under load
        assert sparsity <= 0.3, (
            f"High-load sparsity {sparsity:.3f} exceeds target "
            f"(gate not maintaining selectivity)"
        )

    def test_sparsity_adapts_to_importance(self, gate):
        """
        Test that sparsity adapts based on neuromodulator signals.

        Biology: NE and dopamine modulate DG excitability, affecting
        pattern separation strength.
        """
        context = GateContext(
            session_id="test-session",
            project="ww",
            current_task="testing",
            last_store_time=datetime.now() - timedelta(minutes=5),
            message_count_since_store=5
        )

        # Normal state (balanced)
        normal_state = NeuromodulatorState(
            dopamine_rpe=0.0,
            norepinephrine_gain=1.0,
            acetylcholine_mode="balanced",
            serotonin_mood=0.5,
            inhibition_sparsity=0.3
        )

        # High importance state (high NE, positive RPE)
        high_importance_state = NeuromodulatorState(
            dopamine_rpe=0.8,
            norepinephrine_gain=1.5,
            acetylcholine_mode="encoding",
            serotonin_mood=0.7,
            inhibition_sparsity=0.2  # Lower inhibition = less sparse
        )

        # Test with same inputs under different states
        n_inputs = 50

        normal_stores = 0
        high_importance_stores = 0

        for i in range(n_inputs):
            embedding = np.random.randn(1024).astype(np.float32)

            # Normal state decision
            normal_decision = gate.predict(embedding, context, normal_state, explore=False)
            if normal_decision.action == StorageDecision.STORE:
                normal_stores += 1

            # High importance state decision
            important_decision = gate.predict(embedding, context, high_importance_state, explore=False)
            if important_decision.action == StorageDecision.STORE:
                high_importance_stores += 1

        normal_sparsity = normal_stores / n_inputs
        importance_sparsity = high_importance_stores / n_inputs

        # High importance should reduce sparsity (store more)
        assert importance_sparsity >= normal_sparsity, (
            f"High importance state should reduce sparsity: "
            f"normal={normal_sparsity:.3f}, important={importance_sparsity:.3f}"
        )


# =============================================================================
# 2. Addressing Accuracy Tests
# =============================================================================

class TestAddressingAccuracy:
    """
    Test accuracy of sparse address assignment.

    Biology: Sparse codes must reliably identify specific memories
    while maintaining separation between distinct memories.
    """

    @pytest.fixture
    def gate(self):
        """Create learned gate."""
        # Set seed for reproducible content weight initialization
        np.random.seed(42)
        gate = LearnedMemoryGate(
            neuromod_orchestra=None,
            cold_start_threshold=10,
            use_diagonal_covariance=True
        )
        # Train past cold start
        gate.n_observations = 20
        return gate

    @pytest.fixture
    def context(self):
        """Create gate context."""
        return GateContext(
            session_id="test-session",
            project="ww",
            current_task="testing",
            last_store_time=datetime.now() - timedelta(minutes=5),
            message_count_since_store=3
        )

    @pytest.fixture
    def neuromod_state(self):
        """Create neuromodulator state."""
        return NeuromodulatorState(
            dopamine_rpe=0.5,
            norepinephrine_gain=1.2,
            acetylcholine_mode="balanced",
            serotonin_mood=0.6,
            inhibition_sparsity=0.3
        )

    def test_consistent_addressing(self, gate, context, neuromod_state):
        """
        Test that same input receives consistent address.

        Biology: Sparse codes must be reproducible for reliable retrieval.
        """
        embedding = np.random.randn(1024).astype(np.float32)

        # Get decision multiple times for same input
        decisions = [
            gate.predict(embedding, context, neuromod_state, explore=False)
            for _ in range(10)
        ]

        # All decisions should be identical (deterministic without exploration)
        actions = [d.action for d in decisions]
        probabilities = [d.probability for d in decisions]

        assert len(set(actions)) == 1, "Addressing should be consistent"
        assert np.std(probabilities) < 1e-6, "Probabilities should be identical"

    @pytest.mark.xfail(
        reason="HSA biological validation - discrimination sometimes succeeds "
               "depending on random initialization and training dynamics",
        strict=False
    )
    def test_learned_discrimination(self, gate, context, neuromod_state):
        """
        Test that gate learns to discriminate important vs unimportant inputs.

        Biology: Sparse codes should preferentially allocate to
        important/novel patterns.
        """
        # Train gate with positive examples
        important_embeddings = []
        for i in range(10):
            emb = np.random.randn(1024).astype(np.float32)
            emb[0:100] = 1.0  # Shared important pattern
            emb /= np.linalg.norm(emb)
            important_embeddings.append(emb)

            decision = gate.predict(emb, context, neuromod_state, explore=False)
            memory_id = uuid4()
            gate.register_pending(memory_id, decision.features)
            gate.update(memory_id, utility=1.0)  # High utility

        # Train with negative examples
        unimportant_embeddings = []
        for i in range(10):
            emb = np.random.randn(1024).astype(np.float32)
            emb[0:100] = -1.0  # Shared unimportant pattern
            emb /= np.linalg.norm(emb)
            unimportant_embeddings.append(emb)

            decision = gate.predict(emb, context, neuromod_state, explore=False)
            memory_id = uuid4()
            gate.register_pending(memory_id, decision.features)
            gate.update(memory_id, utility=0.0)  # Low utility

        # Test discrimination on new examples
        important_test = np.random.randn(1024).astype(np.float32)
        important_test[0:100] = 1.0
        important_test /= np.linalg.norm(important_test)

        unimportant_test = np.random.randn(1024).astype(np.float32)
        unimportant_test[0:100] = -1.0
        unimportant_test /= np.linalg.norm(unimportant_test)

        important_decision = gate.predict(important_test, context, neuromod_state, explore=False)
        unimportant_decision = gate.predict(unimportant_test, context, neuromod_state, explore=False)

        # Should assign higher probability to important pattern
        assert important_decision.probability > unimportant_decision.probability, (
            f"Gate should discriminate: important={important_decision.probability:.3f}, "
            f"unimportant={unimportant_decision.probability:.3f}"
        )

    @pytest.mark.xfail(reason="HSA biological validation - pattern diversity depends on random init")
    def test_addressing_capacity(self, gate, context, neuromod_state):
        """
        Test capacity of sparse addressing system.

        Biology: With 2% sparsity and 10x expansion, DG can store
        ~50x more patterns than EC input dimensionality.

        For 1024-dim input, should handle ~50k distinct patterns.
        """
        # For practical test, verify gate can distinguish at least 100 patterns
        n_patterns = 100

        # Use seed for reproducibility
        np.random.seed(42)

        # Generate distinct patterns
        patterns = [np.random.randn(1024).astype(np.float32) for _ in range(n_patterns)]
        for p in patterns:
            p /= np.linalg.norm(p)

        # Get decisions for all patterns
        decisions = [
            gate.predict(p, context, neuromod_state, explore=False)
            for p in patterns
        ]

        # Measure diversity of decisions (via probability distribution)
        probabilities = np.array([d.probability for d in decisions])

        # Should have diverse probabilities (not all the same)
        # With random content weight initialization, different patterns produce different outputs
        prob_variance = np.var(probabilities)

        assert prob_variance > 0.001, (
            f"Gate shows insufficient capacity diversity: var={prob_variance:.6f}"
        )


# =============================================================================
# 3. Interference Resistance Tests
# =============================================================================

class TestInterferenceResistance:
    """
    Test resistance to interference between similar memories.

    Biology: Sparse coding in DG prevents catastrophic interference
    by orthogonalizing similar input patterns.
    """

    @pytest.fixture
    def gate(self):
        """Create learned gate."""
        return LearnedMemoryGate(
            neuromod_orchestra=None,
            cold_start_threshold=10,
            use_diagonal_covariance=True
        )

    @pytest.fixture
    def context(self):
        """Create gate context."""
        return GateContext(
            session_id="test-session",
            project="ww",
            current_task="testing",
            last_store_time=datetime.now() - timedelta(minutes=5),
            message_count_since_store=3
        )

    @pytest.fixture
    def neuromod_state(self):
        """Create neuromodulator state."""
        return NeuromodulatorState(
            dopamine_rpe=0.0,
            norepinephrine_gain=1.0,
            acetylcholine_mode="balanced",
            serotonin_mood=0.5,
            inhibition_sparsity=0.3
        )

    def compute_decision_overlap(self, features1: np.ndarray,
                                features2: np.ndarray) -> float:
        """
        Compute overlap between sparse feature representations.

        Returns proportion of shared active features.
        """
        # Threshold to determine "active" features
        threshold = np.median(features1)

        active1 = features1 > threshold
        active2 = features2 > threshold

        intersection = np.sum(active1 & active2)
        union = np.sum(active1 | active2)

        return intersection / union if union > 0 else 0.0

    @pytest.mark.xfail(reason="HSA biological validation - requires trained content projection")
    def test_similar_inputs_separated(self, gate, context, neuromod_state):
        """
        Test that similar inputs receive separated sparse codes.

        Biology: DG pattern separation orthogonalizes similar inputs
        to prevent interference.
        """
        # Create base pattern
        base = np.random.randn(1024).astype(np.float32)
        base /= np.linalg.norm(base)

        # Create similar patterns (small perturbations)
        n_similar = 10
        similar_patterns = []

        for i in range(n_similar):
            # Add 10% noise
            similar = base + np.random.randn(1024).astype(np.float32) * 0.1
            similar /= np.linalg.norm(similar)
            similar_patterns.append(similar)

        # Get decisions for all patterns
        decisions = [
            gate.predict(p, context, neuromod_state, explore=False)
            for p in similar_patterns
        ]

        # Measure pairwise overlaps in feature representations
        overlaps = []
        for i in range(len(decisions)):
            for j in range(i + 1, len(decisions)):
                overlap = self.compute_decision_overlap(
                    decisions[i].features,
                    decisions[j].features
                )
                overlaps.append(overlap)

        mean_overlap = np.mean(overlaps)

        # Mean overlap should be low (good separation)
        assert mean_overlap < MAX_INTERFERENCE, (
            f"Mean feature overlap {mean_overlap:.3f} exceeds interference "
            f"threshold {MAX_INTERFERENCE} (poor pattern separation)"
        )

    @pytest.mark.xfail(reason="HSA biological validation - requires trained content projection")
    def test_interference_under_sequential_learning(self, gate, context, neuromod_state):
        """
        Test that learning new patterns doesn't catastrophically
        interfere with old patterns.

        Biology: Sparse coding provides natural regularization against
        catastrophic forgetting.
        """
        # Learn first set of patterns
        old_patterns = [
            np.random.randn(1024).astype(np.float32) / np.linalg.norm(np.random.randn(1024))
            for _ in range(20)
        ]

        old_decisions_before = []
        for p in old_patterns:
            decision = gate.predict(p, context, neuromod_state, explore=False)
            old_decisions_before.append(decision)

            # Train on pattern
            memory_id = uuid4()
            gate.register_pending(memory_id, decision.features)
            gate.update(memory_id, utility=0.8)

        # Learn new set of patterns
        new_patterns = [
            np.random.randn(1024).astype(np.float32) / np.linalg.norm(np.random.randn(1024))
            for _ in range(20)
        ]

        for p in new_patterns:
            decision = gate.predict(p, context, neuromod_state, explore=False)

            memory_id = uuid4()
            gate.register_pending(memory_id, decision.features)
            gate.update(memory_id, utility=0.8)

        # Re-test old patterns
        old_decisions_after = [
            gate.predict(p, context, neuromod_state, explore=False)
            for p in old_patterns
        ]

        # Measure change in decisions for old patterns
        probability_changes = [
            abs(before.probability - after.probability)
            for before, after in zip(old_decisions_before, old_decisions_after)
        ]

        mean_change = np.mean(probability_changes)
        max_change = np.max(probability_changes)

        # Old patterns should remain relatively stable
        assert mean_change < 0.15, (
            f"Mean probability change {mean_change:.3f} indicates interference"
        )
        assert max_change < 0.30, (
            f"Max probability change {max_change:.3f} indicates catastrophic forgetting"
        )

    @pytest.mark.xfail(reason="HSA biological validation - requires trained content projection")
    def test_orthogonalization_strength(self, gate, context, neuromod_state):
        """
        Test strength of orthogonalization between patterns.

        Biology: Sparse codes should approach orthogonality for
        maximum separation.
        """
        # Generate random patterns
        n_patterns = 50
        patterns = [
            np.random.randn(1024).astype(np.float32) / np.linalg.norm(np.random.randn(1024))
            for _ in range(n_patterns)
        ]

        # Get feature representations
        features = [
            gate.predict(p, context, neuromod_state, explore=False).features
            for p in patterns
        ]

        # Compute pairwise cosine similarities in feature space
        similarities = []
        for i in range(len(features)):
            for j in range(i + 1, len(features)):
                # Normalize features
                f1 = features[i] / (np.linalg.norm(features[i]) + 1e-10)
                f2 = features[j] / (np.linalg.norm(features[j]) + 1e-10)

                similarity = np.dot(f1, f2)
                similarities.append(abs(similarity))

        mean_similarity = np.mean(similarities)

        # Features should be relatively orthogonal (low similarity)
        assert mean_similarity < 0.3, (
            f"Mean feature similarity {mean_similarity:.3f} too high "
            f"(insufficient orthogonalization)"
        )


# =============================================================================
# 4. Sparse Code Properties Tests
# =============================================================================

class TestSparseCodeProperties:
    """
    Test fundamental properties of sparse codes.

    Verifies adherence to theoretical properties that enable
    high capacity and low interference.
    """

    @pytest.fixture
    def gate(self):
        """Create learned gate."""
        return LearnedMemoryGate(
            neuromod_orchestra=None,
            cold_start_threshold=10,
            use_diagonal_covariance=True
        )

    @pytest.mark.xfail(reason="HSA biological validation - requires specific sparse coding properties")
    def test_feature_distribution(self, gate):
        """
        Test that feature distributions support sparse coding.

        Sparse codes should have:
        - Heavy-tailed distributions (few large activations)
        - Majority of features near zero
        """
        context = GateContext(
            session_id="test",
            project="ww",
            current_task="test",
            last_store_time=datetime.now(),
            message_count_since_store=1
        )

        neuromod = NeuromodulatorState(
            dopamine_rpe=0.0,
            norepinephrine_gain=1.0,
            acetylcholine_mode="balanced",
            serotonin_mood=0.5,
            inhibition_sparsity=0.3
        )

        # Generate features for multiple inputs
        n_samples = 100
        all_features = []

        for _ in range(n_samples):
            embedding = np.random.randn(1024).astype(np.float32)
            decision = gate.predict(embedding, context, neuromod, explore=False)
            all_features.append(decision.features)

        all_features = np.array(all_features)

        # Measure feature statistics
        feature_means = np.mean(all_features, axis=0)
        feature_stds = np.std(all_features, axis=0)

        # Compute kurtosis (measure of heavy-tailedness)
        # Sparse distributions have high kurtosis
        centered = all_features - feature_means
        normalized = centered / (feature_stds + 1e-10)
        kurtosis = np.mean(normalized**4, axis=0)

        mean_kurtosis = np.mean(kurtosis)

        # Gaussian is 3.0, sparse is > 3.0
        # Allow for finite sample effects
        assert mean_kurtosis >= 2.5, (
            f"Feature distribution kurtosis {mean_kurtosis:.2f} too low "
            f"(not sufficiently sparse/heavy-tailed)"
        )

    @pytest.mark.xfail(reason="HSA biological validation - requires specific expansion properties")
    def test_expansion_ratio_effective(self, gate):
        """
        Test that feature expansion provides capacity benefits.

        Biology: DG expansion ratio enables greater pattern separation
        capacity than direct encoding.
        """
        # Feature dimension
        feature_dim = gate.feature_dim  # 1143

        # Input dimension (embedding)
        input_dim = 1024

        # Expansion ratio
        expansion = feature_dim / input_dim

        # Should achieve meaningful expansion
        # (not necessarily 10x like DG, but > 1x)
        assert expansion > 1.0, (
            f"Feature expansion {expansion:.2f}x insufficient "
            f"(should expand input space)"
        )

    def test_biological_sparsity_target(self):
        """
        Verify biological sparsity target constant.
        """
        # DG physiological sparsity
        assert TARGET_SPARSITY == pytest.approx(0.02, abs=0.001)

        # Expansion ratio
        assert DG_EXPANSION_RATIO == 10

        # Interference threshold
        assert MAX_INTERFERENCE <= 0.2  # < 20% overlap
